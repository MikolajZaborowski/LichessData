{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f0c5c6",
   "metadata": {},
   "source": [
    "# FE + Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b902a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "# Clasification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score\n",
    "# Best_searches\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Standarization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras import models\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e086c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arrow\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6358258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Chess_data_basic.csv\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d64554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4789"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df[\"black_player_name\"]+df[\"white_player_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad84cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "rated                  0\n",
       "variant                0\n",
       "speed                  0\n",
       "createdAt              0\n",
       "lastMoveAt             0\n",
       "status                 0\n",
       "winner               250\n",
       "moves                  1\n",
       "clock                  0\n",
       "movesperplayer         0\n",
       "white_player_name      0\n",
       "white_ranking          0\n",
       "black_player_name      0\n",
       "black_ranking          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3c9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_with_offset(date_str):\n",
    "    return arrow.get(date_str).datetime\n",
    "\n",
    "for i in ['createdAt', 'lastMoveAt']:\n",
    "    df[i] = df[i].apply(convert_date_with_offset)\n",
    "    \n",
    "# Create Gametime column\n",
    "df[\"Gametime\"] = df[\"lastMoveAt\"] - df[\"createdAt\"]\n",
    "# Handle Gametime column\n",
    "df['Gametime'] = pd.to_timedelta(df['Gametime'])\n",
    "\n",
    "rounding = lambda x: round(x, 1)\n",
    "\n",
    "df['Gametime'] = df['Gametime'].dt.total_seconds().apply(rounding)\n",
    "df['timepermove']=(df['Gametime']/df[\"movesperplayer\"]).apply(rounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43304c07",
   "metadata": {},
   "source": [
    "next think to do is taking insight from moves column, there is a lot of possibility but i will concentrate on:\n",
    "1) Change data to perspective of one player\n",
    "1) cheking for long or short castle\n",
    "2) taking number of moves before castle devided by 100  ( if no castle - values set to 1 )\n",
    "3) groping by opening (for this project i will take in count only first 4 moves - 2 moves per side )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b957b3ba",
   "metadata": {},
   "source": [
    "## Handle NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b45191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "rated                0\n",
       "variant              0\n",
       "speed                0\n",
       "createdAt            0\n",
       "lastMoveAt           0\n",
       "status               0\n",
       "winner               0\n",
       "moves                0\n",
       "clock                0\n",
       "movesperplayer       0\n",
       "white_player_name    0\n",
       "white_ranking        0\n",
       "black_player_name    0\n",
       "black_ranking        0\n",
       "Gametime             0\n",
       "timepermove          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only timepermove colum had NA values (just one), expect winner, where NA == DRAW\n",
    "df.dropna(subset=['timepermove'],inplace=True)\n",
    "\n",
    "df = df.fillna(\"draw\")\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a9d55",
   "metadata": {},
   "source": [
    "# Checking for side castle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201e760",
   "metadata": {},
   "source": [
    "kingside castle ( short ) is O-O in moves notation and queenside castle ( long ) is O-O-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a261a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moves_column(df):\n",
    "    df[\"moves\"] = df[\"moves\"].str.split(\" \")\n",
    "    df[\"white_moves\"]=df[\"moves\"].apply(lambda x: x[::2])\n",
    "    df[\"black_moves\"]=df[\"moves\"].apply(lambda x: x[1::2])\n",
    "    return df\n",
    "\n",
    "df = moves_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b26380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def castle( df ):\n",
    "    color_list = []\n",
    "    my_short = []\n",
    "    my_long = []\n",
    "    enemy_short = []\n",
    "    enemy_long = []\n",
    "    \n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if df[\"white_player_name\"][index]==\"EvilSaintPL\":\n",
    "            color_list.append(1)\n",
    "        else:\n",
    "            color_list.append(0)\n",
    "        \n",
    "        if df[\"white_player_name\"][index]==\"EvilSaintPL\" and (\"O-O\" in df[\"white_moves\"][index]):\n",
    "            my_short.append(1)\n",
    "            my_long.append(0)\n",
    "        elif df[\"white_player_name\"][index]==\"EvilSaintPL\" and (\"O-O-O\" in df[\"white_moves\"][index]):\n",
    "            my_long.append(1)\n",
    "            my_short.append(0)\n",
    "        elif df[\"black_player_name\"][index]==\"EvilSaintPL\" and (\"O-O\" in df[\"black_moves\"][index]):\n",
    "            my_short.append(1)\n",
    "            my_long.append(0)\n",
    "        elif df[\"black_player_name\"][index]==\"EvilSaintPL\" and (\"O-O-O\" in df[\"black_moves\"][index]):\n",
    "            my_long.append(1)\n",
    "            my_short.append(0)\n",
    "        else:\n",
    "            my_long.append(0)\n",
    "            my_short.append(0)\n",
    "        \n",
    "        if df[\"white_player_name\"][index]!=\"EvilSaintPL\" and (\"O-O\" in df[\"white_moves\"][index]):\n",
    "            enemy_short.append(1)\n",
    "            enemy_long.append(0)\n",
    "        elif df[\"white_player_name\"][index]!=\"EvilSaintPL\" and (\"O-O-O\" in df[\"white_moves\"][index]):\n",
    "            enemy_long.append(1)\n",
    "            enemy_short.append(0)\n",
    "        elif df[\"black_player_name\"][index]!=\"EvilSaintPL\" and (\"O-O\" in df[\"black_moves\"][index]):\n",
    "            enemy_short.append(1)\n",
    "            enemy_long.append(0)\n",
    "        elif df[\"black_player_name\"][index]!=\"EvilSaintPL\" and (\"O-O-O\" in df[\"black_moves\"][index]):\n",
    "            enemy_long.append(1)\n",
    "            enemy_short.append(0)\n",
    "        else:\n",
    "            enemy_long.append(0)\n",
    "            enemy_short.append(0)        \n",
    "        \n",
    "    df[\"my_kingcastle\"]=my_short\n",
    "    df[\"my_queencastle\"]=my_long\n",
    "    df[\"enemy_kingcastle\"]=enemy_short\n",
    "    df[\"enemy_queencastle\"]=enemy_long\n",
    "    df[\"my_color\"]=color_list\n",
    "    return df\n",
    "        \n",
    "df = castle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5974f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575528a6",
   "metadata": {},
   "source": [
    "# num of moves before castle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b3639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_of_first_occurrence(lst):\n",
    "    elements = [\"O-O\", \"O-O-O\"]\n",
    "    for element in elements:\n",
    "        if element in lst:\n",
    "            return lst.index(element)\n",
    "    return len(lst) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1eed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moves_before_castle( df ):\n",
    "    df[\"White_moves_before_castle\"] = df[\"white_moves\"].apply(find_index_of_first_occurrence)\n",
    "    df[\"Black_moves_before_castle\"] = df[\"black_moves\"].apply(find_index_of_first_occurrence)\n",
    "    \n",
    "    my_moves_before = []\n",
    "    enemy_moves_before = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if df[\"my_color\"][index]==1:\n",
    "            my_moves_before.append(df[\"White_moves_before_castle\"][index])\n",
    "            enemy_moves_before.append(df[\"Black_moves_before_castle\"][index])\n",
    "        else:\n",
    "            my_moves_before.append(df[\"Black_moves_before_castle\"][index])\n",
    "            enemy_moves_before.append(df[\"White_moves_before_castle\"][index])\n",
    "            \n",
    "    df[\"my_moves_before_castle\"] = my_moves_before\n",
    "    df[\"enemy_moves_before_castle\"]= enemy_moves_before\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if df[\"my_moves_before_castle\"][index]>(df[\"movesperplayer\"][index]):\n",
    "            df[\"my_moves_before_castle\"][index]=100\n",
    "        elif df[\"enemy_moves_before_castle\"][index]>(df[\"movesperplayer\"][index]):\n",
    "            df[\"enemy_moves_before_castle\"][index]=100\n",
    "    \n",
    "    df[\"my_moves_before_castle\"] = df[\"my_moves_before_castle\"]/(100)\n",
    "    df[\"enemy_moves_before_castle\"] = df[\"enemy_moves_before_castle\"]/(100)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df=moves_before_castle( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bf56dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>variant</th>\n",
       "      <th>speed</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>lastMoveAt</th>\n",
       "      <th>status</th>\n",
       "      <th>winner</th>\n",
       "      <th>moves</th>\n",
       "      <th>clock</th>\n",
       "      <th>movesperplayer</th>\n",
       "      <th>white_player_name</th>\n",
       "      <th>white_ranking</th>\n",
       "      <th>black_player_name</th>\n",
       "      <th>black_ranking</th>\n",
       "      <th>Gametime</th>\n",
       "      <th>timepermove</th>\n",
       "      <th>white_moves</th>\n",
       "      <th>black_moves</th>\n",
       "      <th>my_kingcastle</th>\n",
       "      <th>my_queencastle</th>\n",
       "      <th>enemy_kingcastle</th>\n",
       "      <th>enemy_queencastle</th>\n",
       "      <th>my_color</th>\n",
       "      <th>White_moves_before_castle</th>\n",
       "      <th>Black_moves_before_castle</th>\n",
       "      <th>my_moves_before_castle</th>\n",
       "      <th>enemy_moves_before_castle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O83cQxfo</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-28 02:33:43.673000+02:00</td>\n",
       "      <td>2023-06-28 02:44:00.722000+02:00</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, e5, Nf3, Nc6, Bc4, Nf6, d4, exd4, e5, d5,...</td>\n",
       "      <td>300</td>\n",
       "      <td>70</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1753</td>\n",
       "      <td>Leosammie</td>\n",
       "      <td>1735</td>\n",
       "      <td>617.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[e4, Nf3, Bc4, d4, e5, exd6, O-O, Na3, Nb5, Nb...</td>\n",
       "      <td>[e5, Nc6, Nf6, exd4, d5, Qxd6, Be7, Bg4, Qd7, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeBcqcHz</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-28 02:31:45.081000+02:00</td>\n",
       "      <td>2023-06-28 02:33:30.178000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>[Nf3, Nc6, g3, e5, Bg2, e4, Ng1, d5, d3, f5, d...</td>\n",
       "      <td>300</td>\n",
       "      <td>18</td>\n",
       "      <td>convict-19</td>\n",
       "      <td>1801</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1758</td>\n",
       "      <td>105.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[Nf3, g3, Bg2, Ng1, d3, dxe4, Nc3, Bg5, Bxf6, ...</td>\n",
       "      <td>[Nc6, e5, e4, d5, f5, fxe4, Nf6, Be7, Bxf6, Qx...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hDXG2PXc</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-26 00:04:39.921000+02:00</td>\n",
       "      <td>2023-06-26 00:07:33.812000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, e5, Nc3, Nf6, Nf3, Nc6, d4, exd4, Nxd4, N...</td>\n",
       "      <td>300</td>\n",
       "      <td>15</td>\n",
       "      <td>Gabaz</td>\n",
       "      <td>1790</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1764</td>\n",
       "      <td>173.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>[e4, Nc3, Nf3, d4, Nxd4, Qxd4, Bg5, Bh4, Qe3, ...</td>\n",
       "      <td>[e5, Nf6, Nc6, exd4, Nxd4, Qe7, h6, c5, d5, Bd...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W45quoHn</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-26 00:03:49.331000+02:00</td>\n",
       "      <td>2023-06-26 00:04:36.328000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>[e4, g6, d4, Bg7, Nf3, d6, Bf4, Bd7, Bd3, a6, ...</td>\n",
       "      <td>300</td>\n",
       "      <td>12</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1771</td>\n",
       "      <td>Harrybrave</td>\n",
       "      <td>1738</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[e4, d4, Nf3, Bf4, Bd3, O-O, c3, e5, Qd2, Qxf4...</td>\n",
       "      <td>[g6, Bg7, d6, Bd7, a6, b5, Nf6, Nh5, Nxf4, O-O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9L3EOwxU</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-26 00:00:44.085000+02:00</td>\n",
       "      <td>2023-06-26 00:03:44.461000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, e5, Nf3, Nc6, d4, exd4, Nxd4, Bc5, Nxc6, ...</td>\n",
       "      <td>300</td>\n",
       "      <td>19</td>\n",
       "      <td>Hakim040</td>\n",
       "      <td>1760</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1778</td>\n",
       "      <td>180.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>[e4, Nf3, d4, Nxd4, Nxc6, Bc4, O-O, b3, exd5, ...</td>\n",
       "      <td>[e5, Nc6, exd4, Bc5, bxc6, Ne7, O-O, d5, cxd5,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>H0YSCwZ7</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-16 02:11:46.517000+02:00</td>\n",
       "      <td>2023-06-16 02:18:46.356000+02:00</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, e5, Nf3, Nc6, Bc4, Bc5, c3, Nf6, d4, exd4...</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1771</td>\n",
       "      <td>bureksamesom</td>\n",
       "      <td>1793</td>\n",
       "      <td>419.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[e4, Nf3, Bc4, c3, d4, cxd4, Bd2, Nbxd2, e5, O...</td>\n",
       "      <td>[e5, Nc6, Bc5, Nf6, exd4, Bb4+, Bxd2+, O-O, Ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N1DA9esQ</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-16 02:02:24.899000+02:00</td>\n",
       "      <td>2023-06-16 02:11:38.426000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>[e4, e5, Nf3, Nc6, Bc4, d6, c3, Be7, d4, Bg4, ...</td>\n",
       "      <td>300</td>\n",
       "      <td>37</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1778</td>\n",
       "      <td>KancerberoMDQ</td>\n",
       "      <td>1747</td>\n",
       "      <td>553.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[e4, Nf3, Bc4, c3, d4, d5, Bb5+, dxc6, h3, Qd5...</td>\n",
       "      <td>[e5, Nc6, d6, Be7, Bg4, Na5, c6, Nxc6, Bh5, Nf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rfkb0XI6</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-11 02:14:11.027000+02:00</td>\n",
       "      <td>2023-06-11 02:16:56.850000+02:00</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, e5, Nf3, d6, Bc4, h6, d4, exd4, Nxd4, c5,...</td>\n",
       "      <td>300</td>\n",
       "      <td>28</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1772</td>\n",
       "      <td>edwinorlando11</td>\n",
       "      <td>1766</td>\n",
       "      <td>165.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>[e4, Nf3, Bc4, d4, Nxd4, Qh5, Nf3, O-O, Bb5, B...</td>\n",
       "      <td>[e5, d6, h6, exd4, c5, Qf6, Nc6, Be6, a6, bxc6...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F2C4Mm1C</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-11 02:11:42.973000+02:00</td>\n",
       "      <td>2023-06-11 02:14:01.606000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, e5, Nf3, Nc6, d4, exd4, Nxd4, Bc5, Nxc6, ...</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>kasper023</td>\n",
       "      <td>1860</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1777</td>\n",
       "      <td>138.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>[e4, Nf3, d4, Nxd4, Nxc6, Bd3, Bg5, Nc3, Bh4, ...</td>\n",
       "      <td>[e5, Nc6, exd4, Bc5, bxc6, Ne7, O-O, h6, Qe8, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c5nqt4zq</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-11 02:02:10.147000+02:00</td>\n",
       "      <td>2023-06-11 02:11:27.197000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>[d4, d5, Nf3, Nf6, e3, Bg4, h3, Bxf3, Qxf3, Nc...</td>\n",
       "      <td>300</td>\n",
       "      <td>51</td>\n",
       "      <td>elaprendizdeljaque</td>\n",
       "      <td>1735</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1771</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>[d4, Nf3, e3, h3, Qxf3, Bb5, Bxc6+, Nd2, O-O, ...</td>\n",
       "      <td>[d5, Nf6, Bg4, Bxf3, Nc6, a6, bxc6, Rb8, e6, Q...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yDvYTfB6</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-11 01:53:11.541000+02:00</td>\n",
       "      <td>2023-06-11 02:01:24.299000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>[e4, e5, Nf3, Nc6, Nc3, Nf6, Bc4, d6, h3, Be7,...</td>\n",
       "      <td>300</td>\n",
       "      <td>32</td>\n",
       "      <td>juvydina</td>\n",
       "      <td>1718</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1767</td>\n",
       "      <td>492.8</td>\n",
       "      <td>15.4</td>\n",
       "      <td>[e4, Nf3, Nc3, Bc4, h3, d3, O-O, Nh2, f4, fxe5...</td>\n",
       "      <td>[e5, Nc6, Nf6, d6, Be7, h6, O-O, Bd7, Nh7, Nxe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6tAOifYq</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-11 01:51:37.748000+02:00</td>\n",
       "      <td>2023-06-11 01:52:59.734000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>[e4, c6, d4, d5, exd5, cxd5, c4, Nc6, Nc3, dxc...</td>\n",
       "      <td>300</td>\n",
       "      <td>9</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1773</td>\n",
       "      <td>sammie_chika</td>\n",
       "      <td>1726</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>[e4, d4, exd5, c4, Nc3, d5, Qa4+, Qxb4, Nf3, N...</td>\n",
       "      <td>[c6, d5, cxd5, Nc6, dxc4, Nb4, Bd7, b5, e5, Bxb4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9hVMNcVe</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-11 01:47:37.756000+02:00</td>\n",
       "      <td>2023-06-11 01:50:44.879000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, c6, d4, d5, exd5, cxd5, c4, Bf5, Nc3, e6,...</td>\n",
       "      <td>300</td>\n",
       "      <td>19</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1768</td>\n",
       "      <td>Zulpijaytanah</td>\n",
       "      <td>1725</td>\n",
       "      <td>187.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>[e4, d4, exd5, c4, Nc3, cxd5, Bf4, Rc1, Rxc3, ...</td>\n",
       "      <td>[c6, d5, cxd5, Bf5, e6, exd5, Bb4, Bxc3+, Nc6,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VQ8Gu3DP</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-11 01:41:24.160000+02:00</td>\n",
       "      <td>2023-06-11 01:47:35.198000+02:00</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>[e4, e6, d4, d5, exd5, exd5, Nc3, Nf6, Nf3, Bb...</td>\n",
       "      <td>300</td>\n",
       "      <td>58</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1774</td>\n",
       "      <td>Spideman87</td>\n",
       "      <td>1771</td>\n",
       "      <td>371.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>[e4, d4, exd5, Nc3, Nf3, Bg5, Bd3, Be3, Qd2, O...</td>\n",
       "      <td>[e6, d5, exd5, Nf6, Bb4, O-O, Re8+, Ng4, Qf6, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ez43SfyZ</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-07 02:51:15.240000+02:00</td>\n",
       "      <td>2023-06-07 02:56:19.584000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>[d4, d5, c4, c6, Nc3, Bf5, Qb3, Qc7, cxd5, Nf6...</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>ValJor</td>\n",
       "      <td>1748</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1768</td>\n",
       "      <td>304.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>[d4, c4, Nc3, Qb3, cxd5, dxc6, e3, dxe5, Be2, ...</td>\n",
       "      <td>[d5, c6, Bf5, Qc7, Nf6, Nxc6, e5, Nxe5, Bd6, O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gLAlZFFx</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-07 02:46:30.660000+02:00</td>\n",
       "      <td>2023-06-07 02:50:20.872000+02:00</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>[d4, d5, c4, c6, Bf4, Bf5, e3, e6, Nf3, Nd7, h...</td>\n",
       "      <td>300</td>\n",
       "      <td>27</td>\n",
       "      <td>da7om1416</td>\n",
       "      <td>1756</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1763</td>\n",
       "      <td>230.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>[d4, c4, Bf4, e3, Nf3, h3, Be2, cxd5, O-O, Qb3...</td>\n",
       "      <td>[d5, c6, Bf5, e6, Nd7, Ngf6, Be7, cxd5, Rc8, Q...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5uWQhBiF</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-07 02:35:57.646000+02:00</td>\n",
       "      <td>2023-06-07 02:46:22.157000+02:00</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>[e4, e6, d4, d5, exd5, exd5, Nc3, Nf6, Nf3, Bb...</td>\n",
       "      <td>300</td>\n",
       "      <td>91</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1768</td>\n",
       "      <td>sebaagv</td>\n",
       "      <td>1804</td>\n",
       "      <td>624.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>[e4, d4, exd5, Nc3, Nf3, Bg5, a3, bxc3, Be3, B...</td>\n",
       "      <td>[e6, d5, exd5, Nf6, Bb4, O-O, Bxc3+, h6, Bf5, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>uxE9ud30</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-01 18:22:19.034000+02:00</td>\n",
       "      <td>2023-06-01 18:26:26.523000+02:00</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>[e4, e5, d3, Nc6, Be3, d5, exd5, Qxd5, Nc3, Bb...</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>zajc1</td>\n",
       "      <td>1750</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1763</td>\n",
       "      <td>247.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[e4, d3, Be3, exd5, Nc3, Ne2, a3, Bxe2, bxc3, ...</td>\n",
       "      <td>[e5, Nc6, d5, Qxd5, Bb4, Bg4, Bxe2, Bxc3+, f5,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DRiFLKVy</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-01 18:07:38.533000+02:00</td>\n",
       "      <td>2023-06-01 18:17:22.238000+02:00</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>[c4, e5, Nc3, Nf6, d3, d5, b3, d4, Na4, Bd7, N...</td>\n",
       "      <td>300</td>\n",
       "      <td>69</td>\n",
       "      <td>lc1408</td>\n",
       "      <td>1759</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1768</td>\n",
       "      <td>583.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>[c4, Nc3, d3, b3, Na4, Nb2, Bd2, h3, e4, Be2, ...</td>\n",
       "      <td>[e5, Nf6, d5, d4, Bd7, a6, b5, Be7, b4, a5, O-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nSkSOyKk</td>\n",
       "      <td>True</td>\n",
       "      <td>standard</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-01 16:44:58.061000+02:00</td>\n",
       "      <td>2023-06-01 16:50:56.745000+02:00</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, e5, Nf3, Nc6, Bc4, Nf6, d3, Bb4+, c3, Bc5...</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1763</td>\n",
       "      <td>Oncedead</td>\n",
       "      <td>1742</td>\n",
       "      <td>358.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[e4, Nf3, Bc4, d3, c3, d4, cxd4, Bd2, Nbxd2, e...</td>\n",
       "      <td>[e5, Nc6, Nf6, Bb4+, Bc5, exd4, Bb4+, Bxd2+, O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  rated   variant  speed                         createdAt  \\\n",
       "0   O83cQxfo   True  standard  blitz  2023-06-28 02:33:43.673000+02:00   \n",
       "1   KeBcqcHz   True  standard  blitz  2023-06-28 02:31:45.081000+02:00   \n",
       "2   hDXG2PXc   True  standard  blitz  2023-06-26 00:04:39.921000+02:00   \n",
       "3   W45quoHn   True  standard  blitz  2023-06-26 00:03:49.331000+02:00   \n",
       "4   9L3EOwxU   True  standard  blitz  2023-06-26 00:00:44.085000+02:00   \n",
       "5   H0YSCwZ7   True  standard  blitz  2023-06-16 02:11:46.517000+02:00   \n",
       "6   N1DA9esQ   True  standard  blitz  2023-06-16 02:02:24.899000+02:00   \n",
       "7   Rfkb0XI6   True  standard  blitz  2023-06-11 02:14:11.027000+02:00   \n",
       "8   F2C4Mm1C   True  standard  blitz  2023-06-11 02:11:42.973000+02:00   \n",
       "9   c5nqt4zq   True  standard  blitz  2023-06-11 02:02:10.147000+02:00   \n",
       "10  yDvYTfB6   True  standard  blitz  2023-06-11 01:53:11.541000+02:00   \n",
       "11  6tAOifYq   True  standard  blitz  2023-06-11 01:51:37.748000+02:00   \n",
       "12  9hVMNcVe   True  standard  blitz  2023-06-11 01:47:37.756000+02:00   \n",
       "13  VQ8Gu3DP   True  standard  blitz  2023-06-11 01:41:24.160000+02:00   \n",
       "14  Ez43SfyZ   True  standard  blitz  2023-06-07 02:51:15.240000+02:00   \n",
       "15  gLAlZFFx   True  standard  blitz  2023-06-07 02:46:30.660000+02:00   \n",
       "16  5uWQhBiF   True  standard  blitz  2023-06-07 02:35:57.646000+02:00   \n",
       "17  uxE9ud30   True  standard  blitz  2023-06-01 18:22:19.034000+02:00   \n",
       "18  DRiFLKVy   True  standard  blitz  2023-06-01 18:07:38.533000+02:00   \n",
       "19  nSkSOyKk   True  standard  blitz  2023-06-01 16:44:58.061000+02:00   \n",
       "\n",
       "                          lastMoveAt     status winner  \\\n",
       "0   2023-06-28 02:44:00.722000+02:00  outoftime  white   \n",
       "1   2023-06-28 02:33:30.178000+02:00     resign  white   \n",
       "2   2023-06-26 00:07:33.812000+02:00     resign  white   \n",
       "3   2023-06-26 00:04:36.328000+02:00     resign  black   \n",
       "4   2023-06-26 00:03:44.461000+02:00     resign  white   \n",
       "5   2023-06-16 02:18:46.356000+02:00       mate  white   \n",
       "6   2023-06-16 02:11:38.426000+02:00     resign  black   \n",
       "7   2023-06-11 02:16:56.850000+02:00       mate  white   \n",
       "8   2023-06-11 02:14:01.606000+02:00     resign  white   \n",
       "9   2023-06-11 02:11:27.197000+02:00     resign  black   \n",
       "10  2023-06-11 02:01:24.299000+02:00     resign  black   \n",
       "11  2023-06-11 01:52:59.734000+02:00     resign  black   \n",
       "12  2023-06-11 01:50:44.879000+02:00     resign  white   \n",
       "13  2023-06-11 01:47:35.198000+02:00       mate  black   \n",
       "14  2023-06-07 02:56:19.584000+02:00     resign  black   \n",
       "15  2023-06-07 02:50:20.872000+02:00       mate  black   \n",
       "16  2023-06-07 02:46:22.157000+02:00       mate  black   \n",
       "17  2023-06-01 18:26:26.523000+02:00     resign  black   \n",
       "18  2023-06-01 18:17:22.238000+02:00  outoftime  white   \n",
       "19  2023-06-01 16:50:56.745000+02:00       mate  white   \n",
       "\n",
       "                                                moves  clock  movesperplayer  \\\n",
       "0   [e4, e5, Nf3, Nc6, Bc4, Nf6, d4, exd4, e5, d5,...    300              70   \n",
       "1   [Nf3, Nc6, g3, e5, Bg2, e4, Ng1, d5, d3, f5, d...    300              18   \n",
       "2   [e4, e5, Nc3, Nf6, Nf3, Nc6, d4, exd4, Nxd4, N...    300              15   \n",
       "3   [e4, g6, d4, Bg7, Nf3, d6, Bf4, Bd7, Bd3, a6, ...    300              12   \n",
       "4   [e4, e5, Nf3, Nc6, d4, exd4, Nxd4, Bc5, Nxc6, ...    300              19   \n",
       "5   [e4, e5, Nf3, Nc6, Bc4, Bc5, c3, Nf6, d4, exd4...    300              30   \n",
       "6   [e4, e5, Nf3, Nc6, Bc4, d6, c3, Be7, d4, Bg4, ...    300              37   \n",
       "7   [e4, e5, Nf3, d6, Bc4, h6, d4, exd4, Nxd4, c5,...    300              28   \n",
       "8   [e4, e5, Nf3, Nc6, d4, exd4, Nxd4, Bc5, Nxc6, ...    300              20   \n",
       "9   [d4, d5, Nf3, Nf6, e3, Bg4, h3, Bxf3, Qxf3, Nc...    300              51   \n",
       "10  [e4, e5, Nf3, Nc6, Nc3, Nf6, Bc4, d6, h3, Be7,...    300              32   \n",
       "11  [e4, c6, d4, d5, exd5, cxd5, c4, Nc6, Nc3, dxc...    300               9   \n",
       "12  [e4, c6, d4, d5, exd5, cxd5, c4, Bf5, Nc3, e6,...    300              19   \n",
       "13  [e4, e6, d4, d5, exd5, exd5, Nc3, Nf6, Nf3, Bb...    300              58   \n",
       "14  [d4, d5, c4, c6, Nc3, Bf5, Qb3, Qc7, cxd5, Nf6...    300              30   \n",
       "15  [d4, d5, c4, c6, Bf4, Bf5, e3, e6, Nf3, Nd7, h...    300              27   \n",
       "16  [e4, e6, d4, d5, exd5, exd5, Nc3, Nf6, Nf3, Bb...    300              91   \n",
       "17  [e4, e5, d3, Nc6, Be3, d5, exd5, Qxd5, Nc3, Bb...    300              30   \n",
       "18  [c4, e5, Nc3, Nf6, d3, d5, b3, d4, Na4, Bd7, N...    300              69   \n",
       "19  [e4, e5, Nf3, Nc6, Bc4, Nf6, d3, Bb4+, c3, Bc5...    300              30   \n",
       "\n",
       "     white_player_name  white_ranking black_player_name  black_ranking  \\\n",
       "0          EvilSaintPL           1753         Leosammie           1735   \n",
       "1           convict-19           1801       EvilSaintPL           1758   \n",
       "2                Gabaz           1790       EvilSaintPL           1764   \n",
       "3          EvilSaintPL           1771        Harrybrave           1738   \n",
       "4             Hakim040           1760       EvilSaintPL           1778   \n",
       "5          EvilSaintPL           1771      bureksamesom           1793   \n",
       "6          EvilSaintPL           1778     KancerberoMDQ           1747   \n",
       "7          EvilSaintPL           1772    edwinorlando11           1766   \n",
       "8            kasper023           1860       EvilSaintPL           1777   \n",
       "9   elaprendizdeljaque           1735       EvilSaintPL           1771   \n",
       "10            juvydina           1718       EvilSaintPL           1767   \n",
       "11         EvilSaintPL           1773      sammie_chika           1726   \n",
       "12         EvilSaintPL           1768     Zulpijaytanah           1725   \n",
       "13         EvilSaintPL           1774        Spideman87           1771   \n",
       "14              ValJor           1748       EvilSaintPL           1768   \n",
       "15           da7om1416           1756       EvilSaintPL           1763   \n",
       "16         EvilSaintPL           1768           sebaagv           1804   \n",
       "17               zajc1           1750       EvilSaintPL           1763   \n",
       "18              lc1408           1759       EvilSaintPL           1768   \n",
       "19         EvilSaintPL           1763          Oncedead           1742   \n",
       "\n",
       "    Gametime  timepermove                                        white_moves  \\\n",
       "0      617.0          8.8  [e4, Nf3, Bc4, d4, e5, exd6, O-O, Na3, Nb5, Nb...   \n",
       "1      105.1          5.8  [Nf3, g3, Bg2, Ng1, d3, dxe4, Nc3, Bg5, Bxf6, ...   \n",
       "2      173.9         11.6  [e4, Nc3, Nf3, d4, Nxd4, Qxd4, Bg5, Bh4, Qe3, ...   \n",
       "3       47.0          3.9  [e4, d4, Nf3, Bf4, Bd3, O-O, c3, e5, Qd2, Qxf4...   \n",
       "4      180.4          9.5  [e4, Nf3, d4, Nxd4, Nxc6, Bc4, O-O, b3, exd5, ...   \n",
       "5      419.8         14.0  [e4, Nf3, Bc4, c3, d4, cxd4, Bd2, Nbxd2, e5, O...   \n",
       "6      553.5         15.0  [e4, Nf3, Bc4, c3, d4, d5, Bb5+, dxc6, h3, Qd5...   \n",
       "7      165.8          5.9  [e4, Nf3, Bc4, d4, Nxd4, Qh5, Nf3, O-O, Bb5, B...   \n",
       "8      138.6          6.9  [e4, Nf3, d4, Nxd4, Nxc6, Bd3, Bg5, Nc3, Bh4, ...   \n",
       "9      557.0         10.9  [d4, Nf3, e3, h3, Qxf3, Bb5, Bxc6+, Nd2, O-O, ...   \n",
       "10     492.8         15.4  [e4, Nf3, Nc3, Bc4, h3, d3, O-O, Nh2, f4, fxe5...   \n",
       "11      82.0          9.1  [e4, d4, exd5, c4, Nc3, d5, Qa4+, Qxb4, Nf3, N...   \n",
       "12     187.1          9.8  [e4, d4, exd5, c4, Nc3, cxd5, Bf4, Rc1, Rxc3, ...   \n",
       "13     371.0          6.4  [e4, d4, exd5, Nc3, Nf3, Bg5, Bd3, Be3, Qd2, O...   \n",
       "14     304.3         10.1  [d4, c4, Nc3, Qb3, cxd5, dxc6, e3, dxe5, Be2, ...   \n",
       "15     230.2          8.5  [d4, c4, Bf4, e3, Nf3, h3, Be2, cxd5, O-O, Qb3...   \n",
       "16     624.5          6.9  [e4, d4, exd5, Nc3, Nf3, Bg5, a3, bxc3, Be3, B...   \n",
       "17     247.5          8.2  [e4, d3, Be3, exd5, Nc3, Ne2, a3, Bxe2, bxc3, ...   \n",
       "18     583.7          8.5  [c4, Nc3, d3, b3, Na4, Nb2, Bd2, h3, e4, Be2, ...   \n",
       "19     358.7         12.0  [e4, Nf3, Bc4, d3, c3, d4, cxd4, Bd2, Nbxd2, e...   \n",
       "\n",
       "                                          black_moves  my_kingcastle  \\\n",
       "0   [e5, Nc6, Nf6, exd4, d5, Qxd6, Be7, Bg4, Qd7, ...              1   \n",
       "1   [Nc6, e5, e4, d5, f5, fxe4, Nf6, Be7, Bxf6, Qx...              0   \n",
       "2   [e5, Nf6, Nc6, exd4, Nxd4, Qe7, h6, c5, d5, Bd...              0   \n",
       "3   [g6, Bg7, d6, Bd7, a6, b5, Nf6, Nh5, Nxf4, O-O...              1   \n",
       "4   [e5, Nc6, exd4, Bc5, bxc6, Ne7, O-O, d5, cxd5,...              1   \n",
       "5   [e5, Nc6, Bc5, Nf6, exd4, Bb4+, Bxd2+, O-O, Ne...              1   \n",
       "6   [e5, Nc6, d6, Be7, Bg4, Na5, c6, Nxc6, Bh5, Nf...              1   \n",
       "7   [e5, d6, h6, exd4, c5, Qf6, Nc6, Be6, a6, bxc6...              1   \n",
       "8   [e5, Nc6, exd4, Bc5, bxc6, Ne7, O-O, h6, Qe8, ...              1   \n",
       "9   [d5, Nf6, Bg4, Bxf3, Nc6, a6, bxc6, Rb8, e6, Q...              1   \n",
       "10  [e5, Nc6, Nf6, d6, Be7, h6, O-O, Bd7, Nh7, Nxe...              1   \n",
       "11  [c6, d5, cxd5, Nc6, dxc4, Nb4, Bd7, b5, e5, Bxb4]              0   \n",
       "12  [c6, d5, cxd5, Bf5, e6, exd5, Bb4, Bxc3+, Nc6,...              1   \n",
       "13  [e6, d5, exd5, Nf6, Bb4, O-O, Re8+, Ng4, Qf6, ...              1   \n",
       "14  [d5, c6, Bf5, Qc7, Nf6, Nxc6, e5, Nxe5, Bd6, O...              1   \n",
       "15  [d5, c6, Bf5, e6, Nd7, Ngf6, Be7, cxd5, Rc8, Q...              0   \n",
       "16  [e6, d5, exd5, Nf6, Bb4, O-O, Bxc3+, h6, Bf5, ...              1   \n",
       "17  [e5, Nc6, d5, Qxd5, Bb4, Bg4, Bxe2, Bxc3+, f5,...              1   \n",
       "18  [e5, Nf6, d5, d4, Bd7, a6, b5, Be7, b4, a5, O-...              1   \n",
       "19  [e5, Nc6, Nf6, Bb4+, Bc5, exd4, Bb4+, Bxd2+, O...              1   \n",
       "\n",
       "    my_queencastle  enemy_kingcastle  enemy_queencastle  my_color  \\\n",
       "0                0                 0                  0         1   \n",
       "1                1                 1                  0         0   \n",
       "2                0                 0                  1         0   \n",
       "3                0                 1                  0         1   \n",
       "4                0                 1                  0         0   \n",
       "5                0                 1                  0         1   \n",
       "6                0                 0                  0         1   \n",
       "7                0                 0                  0         1   \n",
       "8                0                 1                  0         0   \n",
       "9                0                 1                  0         0   \n",
       "10               0                 1                  0         0   \n",
       "11               0                 0                  0         1   \n",
       "12               0                 1                  0         1   \n",
       "13               0                 1                  0         1   \n",
       "14               0                 1                  0         0   \n",
       "15               0                 1                  0         0   \n",
       "16               0                 1                  0         1   \n",
       "17               0                 0                  0         0   \n",
       "18               0                 0                  0         0   \n",
       "19               0                 1                  0         1   \n",
       "\n",
       "    White_moves_before_castle  Black_moves_before_castle  \\\n",
       "0                           6                         71   \n",
       "1                          17                         14   \n",
       "2                          12                         16   \n",
       "3                           5                          9   \n",
       "4                           6                          6   \n",
       "5                           9                          7   \n",
       "6                          12                         39   \n",
       "7                           7                         29   \n",
       "8                           9                          6   \n",
       "9                           8                         13   \n",
       "10                          6                          6   \n",
       "11                         11                         11   \n",
       "12                         13                         10   \n",
       "13                          9                          5   \n",
       "14                         10                          9   \n",
       "15                          8                         29   \n",
       "16                         10                          5   \n",
       "17                         32                         14   \n",
       "18                         71                         10   \n",
       "19                         11                          8   \n",
       "\n",
       "    my_moves_before_castle  enemy_moves_before_castle  \n",
       "0                     0.06                       1.00  \n",
       "1                     0.14                       0.17  \n",
       "2                     1.00                       0.12  \n",
       "3                     0.05                       0.09  \n",
       "4                     0.06                       0.06  \n",
       "5                     0.09                       0.07  \n",
       "6                     0.12                       1.00  \n",
       "7                     0.07                       1.00  \n",
       "8                     0.06                       0.09  \n",
       "9                     0.13                       0.08  \n",
       "10                    0.06                       0.06  \n",
       "11                    1.00                       0.11  \n",
       "12                    0.13                       0.10  \n",
       "13                    0.09                       0.05  \n",
       "14                    0.09                       0.10  \n",
       "15                    1.00                       0.08  \n",
       "16                    0.10                       0.05  \n",
       "17                    0.14                       1.00  \n",
       "18                    0.10                       1.00  \n",
       "19                    0.11                       0.08  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9eb6ae",
   "metadata": {},
   "source": [
    "## Grouping by opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c835c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"open4\"] = df[\"moves\"].apply(lambda x: x[:4])\n",
    "df[\"open4\"] = df[\"open4\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95786092",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "white_opens = df[df['white_player_name'] == 'EvilSaintPL'][\"open4\"].value_counts().head(20)\n",
    "black_opens = df[df['black_player_name'] == 'EvilSaintPL'][\"open4\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9406457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterable_opening_list_and_my_ranking( df ):\n",
    "    \n",
    "    openings_list = []\n",
    "    rank_of_evilsaintpl_list = []\n",
    "    evilsaintpl_won = []\n",
    "    enemy_rank_list = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # OPENS1\n",
    "        if df[\"white_player_name\"][index]==\"EvilSaintPL\" and df[\"open4\"][index] in white_opens.index:\n",
    "            openings_list.append(\"White \" + df[\"open4\"][index])\n",
    "        elif  df[\"white_player_name\"][index]!=\"EvilSaintPL\" and df[\"open4\"][index] in black_opens.index:\n",
    "            openings_list.append(\"Black \" + df[\"open4\"][index]) \n",
    "        else:\n",
    "            openings_list.append(\"no opens\")\n",
    "        \n",
    "        # MY RANK AND ENEMY RANK \n",
    "        if df[\"white_player_name\"][index]==\"EvilSaintPL\":\n",
    "            rank_of_evilsaintpl_list.append(df[\"white_ranking\"][index])\n",
    "            enemy_rank_list.append(df[\"black_ranking\"][index])\n",
    "        elif df[\"black_player_name\"][index]==\"EvilSaintPL\":\n",
    "            rank_of_evilsaintpl_list.append(df[\"black_ranking\"][index])\n",
    "            enemy_rank_list.append(df[\"white_ranking\"][index])\n",
    "        else:\n",
    "            print(index)\n",
    "            \n",
    "        # I WON \n",
    "        if df[\"winner\"][index] == 'draw':\n",
    "            evilsaintpl_won.append(0)\n",
    "        elif df[\"white_player_name\"][index]==\"EvilSaintPL\" and df[\"winner\"][index]=='white':\n",
    "            evilsaintpl_won.append(1)\n",
    "        elif  df[\"black_player_name\"][index]==\"EvilSaintPL\" and df[\"winner\"][index]=='black':\n",
    "            evilsaintpl_won.append(1)\n",
    "        else:\n",
    "            evilsaintpl_won.append(-1)\n",
    "            \n",
    "        \n",
    "\n",
    "    df[\"opens1\"]= openings_list\n",
    "    df[\"my_rank\"]= rank_of_evilsaintpl_list\n",
    "    df['i_won'] = evilsaintpl_won\n",
    "    df['enemy_rank'] = enemy_rank_list\n",
    "    \n",
    "    # NEW RANKS FE\n",
    "    df['rank_difference'] = df['my_rank'] - df['enemy_rank']\n",
    "    df['is_higher'] = (df['my_rank'] > df['enemy_rank'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = iterable_opening_list_and_my_ranking(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e13b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dataframe(df):\n",
    "    temp = pd.get_dummies(df[\"opens1\"])\n",
    "    df = pd.concat([df,temp], axis=1)\n",
    "    \n",
    "    df.drop(\"status\",axis=1, inplace=True)\n",
    "    df.drop(labels = [\"opens1\"], axis=1, inplace=True)\n",
    "    df.drop(\"id\",axis=1,inplace=True)\n",
    "    \n",
    "    df = df[df[\"rated\"]==True]\n",
    "    df = df[df[\"white_player_name\"]!=\"YoungCapitan\"]\n",
    "    df = df[df[\"black_player_name\"]!=\"YoungCapitan\"]\n",
    "    df.drop(\"variant\",axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = clear_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a679c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"i_won\"]=df[\"i_won\"]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d828deba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4880, 72)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f72ebd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blitz', 'classical', 'bullet', 'rapid'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.speed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f08be702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankdifftest(df):\n",
    "    \n",
    "    blitz = df[df[\"speed\"]==\"blitz\"].reset_index(drop=True)\n",
    "    classical = df[df[\"speed\"]==\"classical\"].reset_index(drop=True)\n",
    "    bullet = df[df[\"speed\"]==\"bullet\"].reset_index(drop=True)\n",
    "    rapid = df[df[\"speed\"]==\"rapid\"].reset_index(drop=True)\n",
    "    \n",
    "    for speed in [blitz, classical, bullet, rapid]:\n",
    "        rank_resu=list()\n",
    "        for index, row in speed.iterrows():\n",
    "            if index==0:\n",
    "                rank_resu.append(speed[\"my_rank\"][index])\n",
    "            else:\n",
    "                rank_resu.append(speed[\"my_rank\"][index-1])\n",
    "        speed[\"rank_after_game\"]=rank_resu\n",
    "        speed[\"my_rank_diff\"]=speed[\"rank_after_game\"]-speed[\"my_rank\"]\n",
    "    return pd.concat([blitz, classical, bullet, rapid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e92cdd19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = rankdifftest(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a85184fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated</th>\n",
       "      <th>speed</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>lastMoveAt</th>\n",
       "      <th>winner</th>\n",
       "      <th>moves</th>\n",
       "      <th>clock</th>\n",
       "      <th>movesperplayer</th>\n",
       "      <th>white_player_name</th>\n",
       "      <th>white_ranking</th>\n",
       "      <th>black_player_name</th>\n",
       "      <th>black_ranking</th>\n",
       "      <th>Gametime</th>\n",
       "      <th>timepermove</th>\n",
       "      <th>white_moves</th>\n",
       "      <th>black_moves</th>\n",
       "      <th>my_kingcastle</th>\n",
       "      <th>my_queencastle</th>\n",
       "      <th>enemy_kingcastle</th>\n",
       "      <th>enemy_queencastle</th>\n",
       "      <th>my_color</th>\n",
       "      <th>White_moves_before_castle</th>\n",
       "      <th>Black_moves_before_castle</th>\n",
       "      <th>my_moves_before_castle</th>\n",
       "      <th>enemy_moves_before_castle</th>\n",
       "      <th>open4</th>\n",
       "      <th>my_rank</th>\n",
       "      <th>i_won</th>\n",
       "      <th>enemy_rank</th>\n",
       "      <th>rank_difference</th>\n",
       "      <th>is_higher</th>\n",
       "      <th>Black c4 e5 Nc3 Nf6</th>\n",
       "      <th>Black d4 Nf6 Bf4 e6</th>\n",
       "      <th>Black d4 Nf6 Nf3 e6</th>\n",
       "      <th>Black d4 Nf6 c4 e6</th>\n",
       "      <th>Black d4 d5 Bf4 Nf6</th>\n",
       "      <th>Black d4 d5 c4 c6</th>\n",
       "      <th>Black e4 e5 Bc4 Nc6</th>\n",
       "      <th>Black e4 e5 Bc4 Nf6</th>\n",
       "      <th>Black e4 e5 Nc3 Nf6</th>\n",
       "      <th>Black e4 e5 Nf3 Nc6</th>\n",
       "      <th>Black e4 e5 Nf3 Nf6</th>\n",
       "      <th>Black e4 e5 d4 exd4</th>\n",
       "      <th>Black e4 e5 f4 d5</th>\n",
       "      <th>Black e4 e5 f4 exf4</th>\n",
       "      <th>Black e4 e6 Bc4 d5</th>\n",
       "      <th>Black e4 e6 Nc3 d5</th>\n",
       "      <th>Black e4 e6 Nf3 d5</th>\n",
       "      <th>Black e4 e6 d4 d5</th>\n",
       "      <th>Black e4 e6 e5 c5</th>\n",
       "      <th>Black g3 e5 Bg2 Nf6</th>\n",
       "      <th>White e4 c5 Nf3 Nc6</th>\n",
       "      <th>White e4 c5 Nf3 d6</th>\n",
       "      <th>White e4 c5 Nf3 e6</th>\n",
       "      <th>White e4 c6 Nf3 d5</th>\n",
       "      <th>White e4 c6 d4 d5</th>\n",
       "      <th>White e4 d5 Nf3 dxe4</th>\n",
       "      <th>White e4 d5 exd5 Nf6</th>\n",
       "      <th>White e4 d5 exd5 Qxd5</th>\n",
       "      <th>White e4 e5 Nc3 Nc6</th>\n",
       "      <th>White e4 e5 Nc3 Nf6</th>\n",
       "      <th>White e4 e5 Nc3 d6</th>\n",
       "      <th>White e4 e5 Nf3 Bc5</th>\n",
       "      <th>White e4 e5 Nf3 Nc6</th>\n",
       "      <th>White e4 e5 Nf3 Nf6</th>\n",
       "      <th>White e4 e5 Nf3 Qf6</th>\n",
       "      <th>White e4 e5 Nf3 d5</th>\n",
       "      <th>White e4 e5 Nf3 d6</th>\n",
       "      <th>White e4 e6 Nf3 d5</th>\n",
       "      <th>White e4 e6 d4 d5</th>\n",
       "      <th>White e4 g6 d4 Bg7</th>\n",
       "      <th>no opens</th>\n",
       "      <th>rank_after_game</th>\n",
       "      <th>my_rank_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-28 02:33:43.673000+02:00</td>\n",
       "      <td>2023-06-28 02:44:00.722000+02:00</td>\n",
       "      <td>white</td>\n",
       "      <td>[e4, e5, Nf3, Nc6, Bc4, Nf6, d4, exd4, e5, d5,...</td>\n",
       "      <td>300</td>\n",
       "      <td>70</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1753</td>\n",
       "      <td>Leosammie</td>\n",
       "      <td>1735</td>\n",
       "      <td>617.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[e4, Nf3, Bc4, d4, e5, exd6, O-O, Na3, Nb5, Nb...</td>\n",
       "      <td>[e5, Nc6, Nf6, exd4, d5, Qxd6, Be7, Bg4, Qd7, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>e4 e5 Nf3 Nc6</td>\n",
       "      <td>1753</td>\n",
       "      <td>2</td>\n",
       "      <td>1735</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>blitz</td>\n",
       "      <td>2023-06-28 02:31:45.081000+02:00</td>\n",
       "      <td>2023-06-28 02:33:30.178000+02:00</td>\n",
       "      <td>white</td>\n",
       "      <td>[Nf3, Nc6, g3, e5, Bg2, e4, Ng1, d5, d3, f5, d...</td>\n",
       "      <td>300</td>\n",
       "      <td>18</td>\n",
       "      <td>convict-19</td>\n",
       "      <td>1801</td>\n",
       "      <td>EvilSaintPL</td>\n",
       "      <td>1758</td>\n",
       "      <td>105.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[Nf3, g3, Bg2, Ng1, d3, dxe4, Nc3, Bg5, Bxf6, ...</td>\n",
       "      <td>[Nc6, e5, e4, d5, f5, fxe4, Nf6, Be7, Bxf6, Qx...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>Nf3 Nc6 g3 e5</td>\n",
       "      <td>1758</td>\n",
       "      <td>0</td>\n",
       "      <td>1801</td>\n",
       "      <td>-43</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1753</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated  speed                         createdAt  \\\n",
       "0   True  blitz  2023-06-28 02:33:43.673000+02:00   \n",
       "1   True  blitz  2023-06-28 02:31:45.081000+02:00   \n",
       "\n",
       "                         lastMoveAt winner  \\\n",
       "0  2023-06-28 02:44:00.722000+02:00  white   \n",
       "1  2023-06-28 02:33:30.178000+02:00  white   \n",
       "\n",
       "                                               moves  clock  movesperplayer  \\\n",
       "0  [e4, e5, Nf3, Nc6, Bc4, Nf6, d4, exd4, e5, d5,...    300              70   \n",
       "1  [Nf3, Nc6, g3, e5, Bg2, e4, Ng1, d5, d3, f5, d...    300              18   \n",
       "\n",
       "  white_player_name  white_ranking black_player_name  black_ranking  Gametime  \\\n",
       "0       EvilSaintPL           1753         Leosammie           1735     617.0   \n",
       "1        convict-19           1801       EvilSaintPL           1758     105.1   \n",
       "\n",
       "   timepermove                                        white_moves  \\\n",
       "0          8.8  [e4, Nf3, Bc4, d4, e5, exd6, O-O, Na3, Nb5, Nb...   \n",
       "1          5.8  [Nf3, g3, Bg2, Ng1, d3, dxe4, Nc3, Bg5, Bxf6, ...   \n",
       "\n",
       "                                         black_moves  my_kingcastle  \\\n",
       "0  [e5, Nc6, Nf6, exd4, d5, Qxd6, Be7, Bg4, Qd7, ...              1   \n",
       "1  [Nc6, e5, e4, d5, f5, fxe4, Nf6, Be7, Bxf6, Qx...              0   \n",
       "\n",
       "   my_queencastle  enemy_kingcastle  enemy_queencastle  my_color  \\\n",
       "0               0                 0                  0         1   \n",
       "1               1                 1                  0         0   \n",
       "\n",
       "   White_moves_before_castle  Black_moves_before_castle  \\\n",
       "0                          6                         71   \n",
       "1                         17                         14   \n",
       "\n",
       "   my_moves_before_castle  enemy_moves_before_castle          open4  my_rank  \\\n",
       "0                    0.06                       1.00  e4 e5 Nf3 Nc6     1753   \n",
       "1                    0.14                       0.17  Nf3 Nc6 g3 e5     1758   \n",
       "\n",
       "   i_won  enemy_rank  rank_difference  is_higher  Black c4 e5 Nc3 Nf6  \\\n",
       "0      2        1735               18       True                False   \n",
       "1      0        1801              -43      False                False   \n",
       "\n",
       "   Black d4 Nf6 Bf4 e6  Black d4 Nf6 Nf3 e6  Black d4 Nf6 c4 e6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   Black d4 d5 Bf4 Nf6  Black d4 d5 c4 c6  Black e4 e5 Bc4 Nc6  \\\n",
       "0                False              False                False   \n",
       "1                False              False                False   \n",
       "\n",
       "   Black e4 e5 Bc4 Nf6  Black e4 e5 Nc3 Nf6  Black e4 e5 Nf3 Nc6  \\\n",
       "0                False                False                False   \n",
       "1                False                False                False   \n",
       "\n",
       "   Black e4 e5 Nf3 Nf6  Black e4 e5 d4 exd4  Black e4 e5 f4 d5  \\\n",
       "0                False                False              False   \n",
       "1                False                False              False   \n",
       "\n",
       "   Black e4 e5 f4 exf4  Black e4 e6 Bc4 d5  Black e4 e6 Nc3 d5  \\\n",
       "0                False               False               False   \n",
       "1                False               False               False   \n",
       "\n",
       "   Black e4 e6 Nf3 d5  Black e4 e6 d4 d5  Black e4 e6 e5 c5  \\\n",
       "0               False              False              False   \n",
       "1               False              False              False   \n",
       "\n",
       "   Black g3 e5 Bg2 Nf6  White e4 c5 Nf3 Nc6  White e4 c5 Nf3 d6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   White e4 c5 Nf3 e6  White e4 c6 Nf3 d5  White e4 c6 d4 d5  \\\n",
       "0               False               False              False   \n",
       "1               False               False              False   \n",
       "\n",
       "   White e4 d5 Nf3 dxe4  White e4 d5 exd5 Nf6  White e4 d5 exd5 Qxd5  \\\n",
       "0                 False                 False                  False   \n",
       "1                 False                 False                  False   \n",
       "\n",
       "   White e4 e5 Nc3 Nc6  White e4 e5 Nc3 Nf6  White e4 e5 Nc3 d6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   White e4 e5 Nf3 Bc5  White e4 e5 Nf3 Nc6  White e4 e5 Nf3 Nf6  \\\n",
       "0                False                 True                False   \n",
       "1                False                False                False   \n",
       "\n",
       "   White e4 e5 Nf3 Qf6  White e4 e5 Nf3 d5  White e4 e5 Nf3 d6  \\\n",
       "0                False               False               False   \n",
       "1                False               False               False   \n",
       "\n",
       "   White e4 e6 Nf3 d5  White e4 e6 d4 d5  White e4 g6 d4 Bg7  no opens  \\\n",
       "0               False              False               False     False   \n",
       "1               False              False               False      True   \n",
       "\n",
       "   rank_after_game  my_rank_diff  \n",
       "0             1753             0  \n",
       "1             1753            -5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e8a93ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rated', 'speed', 'createdAt', 'lastMoveAt', 'winner', 'moves', 'clock',\n",
       "       'movesperplayer', 'white_player_name', 'white_ranking',\n",
       "       'black_player_name', 'black_ranking', 'Gametime', 'timepermove',\n",
       "       'white_moves', 'black_moves', 'my_kingcastle', 'my_queencastle',\n",
       "       'enemy_kingcastle', 'enemy_queencastle', 'my_color',\n",
       "       'White_moves_before_castle', 'Black_moves_before_castle',\n",
       "       'my_moves_before_castle', 'enemy_moves_before_castle', 'open4',\n",
       "       'my_rank', 'i_won', 'enemy_rank', 'rank_difference', 'is_higher',\n",
       "       'Black c4 e5 Nc3 Nf6', 'Black d4 Nf6 Bf4 e6', 'Black d4 Nf6 Nf3 e6',\n",
       "       'Black d4 Nf6 c4 e6', 'Black d4 d5 Bf4 Nf6', 'Black d4 d5 c4 c6',\n",
       "       'Black e4 e5 Bc4 Nc6', 'Black e4 e5 Bc4 Nf6', 'Black e4 e5 Nc3 Nf6',\n",
       "       'Black e4 e5 Nf3 Nc6', 'Black e4 e5 Nf3 Nf6', 'Black e4 e5 d4 exd4',\n",
       "       'Black e4 e5 f4 d5', 'Black e4 e5 f4 exf4', 'Black e4 e6 Bc4 d5',\n",
       "       'Black e4 e6 Nc3 d5', 'Black e4 e6 Nf3 d5', 'Black e4 e6 d4 d5',\n",
       "       'Black e4 e6 e5 c5', 'Black g3 e5 Bg2 Nf6', 'White e4 c5 Nf3 Nc6',\n",
       "       'White e4 c5 Nf3 d6', 'White e4 c5 Nf3 e6', 'White e4 c6 Nf3 d5',\n",
       "       'White e4 c6 d4 d5', 'White e4 d5 Nf3 dxe4', 'White e4 d5 exd5 Nf6',\n",
       "       'White e4 d5 exd5 Qxd5', 'White e4 e5 Nc3 Nc6', 'White e4 e5 Nc3 Nf6',\n",
       "       'White e4 e5 Nc3 d6', 'White e4 e5 Nf3 Bc5', 'White e4 e5 Nf3 Nc6',\n",
       "       'White e4 e5 Nf3 Nf6', 'White e4 e5 Nf3 Qf6', 'White e4 e5 Nf3 d5',\n",
       "       'White e4 e5 Nf3 d6', 'White e4 e6 Nf3 d5', 'White e4 e6 d4 d5',\n",
       "       'White e4 g6 d4 Bg7', 'no opens', 'rank_after_game', 'my_rank_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9405c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfvisual = df.copy()\n",
    "#dfvisual.drop([\"moves\", \"white_moves\", \"black_moves\",\"open4\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf6bd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfvisual.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b511981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfvisual.to_csv(\"visual.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45a2396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = [ 'i_won','my_color','my_rank', 'enemy_rank','rank_difference', 'is_higher', 'movesperplayer', 'Gametime', 'timepermove','my_kingcastle', 'my_queencastle',\n",
    "       'enemy_kingcastle', 'enemy_queencastle',\n",
    "       'my_moves_before_castle', 'enemy_moves_before_castle', 'no opens', 'Black c4 e5 Nc3 Nf6',\n",
    "       'Black d4 Nf6 Bf4 e6', 'Black d4 Nf6 Nf3 e6', 'Black d4 Nf6 c4 e6',\n",
    "       'Black d4 d5 Bf4 Nf6', 'Black d4 d5 c4 c6', 'Black e4 e5 Bc4 Nc6',\n",
    "       'Black e4 e5 Bc4 Nf6', 'Black e4 e5 Nc3 Nf6', 'Black e4 e5 Nf3 Nc6',\n",
    "       'Black e4 e5 Nf3 Nf6', 'Black e4 e5 d4 exd4', 'Black e4 e5 f4 d5',\n",
    "       'Black e4 e5 f4 exf4', 'Black e4 e6 Bc4 d5', 'Black e4 e6 Nc3 d5',\n",
    "       'Black e4 e6 Nf3 d5', 'Black e4 e6 d4 d5', 'Black e4 e6 e5 c5',\n",
    "       'Black g3 e5 Bg2 Nf6', 'White e4 c5 Nf3 Nc6', 'White e4 c5 Nf3 d6',\n",
    "       'White e4 c5 Nf3 e6', 'White e4 c6 Nf3 d5', 'White e4 c6 d4 d5',\n",
    "       'White e4 d5 Nf3 dxe4', 'White e4 d5 exd5 Nf6', 'White e4 d5 exd5 Qxd5',\n",
    "       'White e4 e5 Nc3 Nc6', 'White e4 e5 Nc3 Nf6', 'White e4 e5 Nc3 d6',\n",
    "       'White e4 e5 Nf3 Bc5', 'White e4 e5 Nf3 Nc6', 'White e4 e5 Nf3 Nf6',\n",
    "       'White e4 e5 Nf3 Qf6', 'White e4 e5 Nf3 d5', 'White e4 e5 Nf3 d6',\n",
    "       'White e4 e6 Nf3 d5', 'White e4 e6 d4 d5', 'White e4 g6 d4 Bg7'  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ab04ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_all = df[model_columns]\n",
    "\n",
    "blitz = df[df[\"speed\"]==\"blitz\"][model_columns]\n",
    "\n",
    "classical = df[df[\"speed\"]==\"classical\"][model_columns]\n",
    "\n",
    "bullet = df[df[\"speed\"]==\"bullet\"][model_columns]\n",
    "\n",
    "rapid = df[df[\"speed\"]==\"rapid\"][model_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef2212fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blitz : (3417, 56),\n",
      "classic: (153, 56),\n",
      "bullet: (975, 56),\n",
      "rapid: (335, 56),\n",
      "full: (4880, 56)\n"
     ]
    }
   ],
   "source": [
    "print(f\"blitz : {blitz.shape},\\nclassic: {classical.shape},\\nbullet: {bullet.shape},\\nrapid: {rapid.shape},\\nfull: {final_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92036698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_won</th>\n",
       "      <th>my_color</th>\n",
       "      <th>my_rank</th>\n",
       "      <th>enemy_rank</th>\n",
       "      <th>rank_difference</th>\n",
       "      <th>is_higher</th>\n",
       "      <th>movesperplayer</th>\n",
       "      <th>Gametime</th>\n",
       "      <th>timepermove</th>\n",
       "      <th>my_kingcastle</th>\n",
       "      <th>my_queencastle</th>\n",
       "      <th>enemy_kingcastle</th>\n",
       "      <th>enemy_queencastle</th>\n",
       "      <th>my_moves_before_castle</th>\n",
       "      <th>enemy_moves_before_castle</th>\n",
       "      <th>no opens</th>\n",
       "      <th>Black c4 e5 Nc3 Nf6</th>\n",
       "      <th>Black d4 Nf6 Bf4 e6</th>\n",
       "      <th>Black d4 Nf6 Nf3 e6</th>\n",
       "      <th>Black d4 Nf6 c4 e6</th>\n",
       "      <th>Black d4 d5 Bf4 Nf6</th>\n",
       "      <th>Black d4 d5 c4 c6</th>\n",
       "      <th>Black e4 e5 Bc4 Nc6</th>\n",
       "      <th>Black e4 e5 Bc4 Nf6</th>\n",
       "      <th>Black e4 e5 Nc3 Nf6</th>\n",
       "      <th>Black e4 e5 Nf3 Nc6</th>\n",
       "      <th>Black e4 e5 Nf3 Nf6</th>\n",
       "      <th>Black e4 e5 d4 exd4</th>\n",
       "      <th>Black e4 e5 f4 d5</th>\n",
       "      <th>Black e4 e5 f4 exf4</th>\n",
       "      <th>Black e4 e6 Bc4 d5</th>\n",
       "      <th>Black e4 e6 Nc3 d5</th>\n",
       "      <th>Black e4 e6 Nf3 d5</th>\n",
       "      <th>Black e4 e6 d4 d5</th>\n",
       "      <th>Black e4 e6 e5 c5</th>\n",
       "      <th>Black g3 e5 Bg2 Nf6</th>\n",
       "      <th>White e4 c5 Nf3 Nc6</th>\n",
       "      <th>White e4 c5 Nf3 d6</th>\n",
       "      <th>White e4 c5 Nf3 e6</th>\n",
       "      <th>White e4 c6 Nf3 d5</th>\n",
       "      <th>White e4 c6 d4 d5</th>\n",
       "      <th>White e4 d5 Nf3 dxe4</th>\n",
       "      <th>White e4 d5 exd5 Nf6</th>\n",
       "      <th>White e4 d5 exd5 Qxd5</th>\n",
       "      <th>White e4 e5 Nc3 Nc6</th>\n",
       "      <th>White e4 e5 Nc3 Nf6</th>\n",
       "      <th>White e4 e5 Nc3 d6</th>\n",
       "      <th>White e4 e5 Nf3 Bc5</th>\n",
       "      <th>White e4 e5 Nf3 Nc6</th>\n",
       "      <th>White e4 e5 Nf3 Nf6</th>\n",
       "      <th>White e4 e5 Nf3 Qf6</th>\n",
       "      <th>White e4 e5 Nf3 d5</th>\n",
       "      <th>White e4 e5 Nf3 d6</th>\n",
       "      <th>White e4 e6 Nf3 d5</th>\n",
       "      <th>White e4 e6 d4 d5</th>\n",
       "      <th>White e4 g6 d4 Bg7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1753</td>\n",
       "      <td>1735</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>617.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1758</td>\n",
       "      <td>1801</td>\n",
       "      <td>-43</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>105.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_won  my_color  my_rank  enemy_rank  rank_difference  is_higher  \\\n",
       "0      2         1     1753        1735               18       True   \n",
       "1      0         0     1758        1801              -43      False   \n",
       "\n",
       "   movesperplayer  Gametime  timepermove  my_kingcastle  my_queencastle  \\\n",
       "0              70     617.0          8.8              1               0   \n",
       "1              18     105.1          5.8              0               1   \n",
       "\n",
       "   enemy_kingcastle  enemy_queencastle  my_moves_before_castle  \\\n",
       "0                 0                  0                    0.06   \n",
       "1                 1                  0                    0.14   \n",
       "\n",
       "   enemy_moves_before_castle  no opens  Black c4 e5 Nc3 Nf6  \\\n",
       "0                       1.00     False                False   \n",
       "1                       0.17      True                False   \n",
       "\n",
       "   Black d4 Nf6 Bf4 e6  Black d4 Nf6 Nf3 e6  Black d4 Nf6 c4 e6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   Black d4 d5 Bf4 Nf6  Black d4 d5 c4 c6  Black e4 e5 Bc4 Nc6  \\\n",
       "0                False              False                False   \n",
       "1                False              False                False   \n",
       "\n",
       "   Black e4 e5 Bc4 Nf6  Black e4 e5 Nc3 Nf6  Black e4 e5 Nf3 Nc6  \\\n",
       "0                False                False                False   \n",
       "1                False                False                False   \n",
       "\n",
       "   Black e4 e5 Nf3 Nf6  Black e4 e5 d4 exd4  Black e4 e5 f4 d5  \\\n",
       "0                False                False              False   \n",
       "1                False                False              False   \n",
       "\n",
       "   Black e4 e5 f4 exf4  Black e4 e6 Bc4 d5  Black e4 e6 Nc3 d5  \\\n",
       "0                False               False               False   \n",
       "1                False               False               False   \n",
       "\n",
       "   Black e4 e6 Nf3 d5  Black e4 e6 d4 d5  Black e4 e6 e5 c5  \\\n",
       "0               False              False              False   \n",
       "1               False              False              False   \n",
       "\n",
       "   Black g3 e5 Bg2 Nf6  White e4 c5 Nf3 Nc6  White e4 c5 Nf3 d6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   White e4 c5 Nf3 e6  White e4 c6 Nf3 d5  White e4 c6 d4 d5  \\\n",
       "0               False               False              False   \n",
       "1               False               False              False   \n",
       "\n",
       "   White e4 d5 Nf3 dxe4  White e4 d5 exd5 Nf6  White e4 d5 exd5 Qxd5  \\\n",
       "0                 False                 False                  False   \n",
       "1                 False                 False                  False   \n",
       "\n",
       "   White e4 e5 Nc3 Nc6  White e4 e5 Nc3 Nf6  White e4 e5 Nc3 d6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   White e4 e5 Nf3 Bc5  White e4 e5 Nf3 Nc6  White e4 e5 Nf3 Nf6  \\\n",
       "0                False                 True                False   \n",
       "1                False                False                False   \n",
       "\n",
       "   White e4 e5 Nf3 Qf6  White e4 e5 Nf3 d5  White e4 e5 Nf3 d6  \\\n",
       "0                False               False               False   \n",
       "1                False               False               False   \n",
       "\n",
       "   White e4 e6 Nf3 d5  White e4 e6 d4 d5  White e4 g6 d4 Bg7  \n",
       "0               False              False               False  \n",
       "1               False              False               False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blitz.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2ccdbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_won</th>\n",
       "      <th>my_color</th>\n",
       "      <th>my_rank</th>\n",
       "      <th>enemy_rank</th>\n",
       "      <th>rank_difference</th>\n",
       "      <th>is_higher</th>\n",
       "      <th>movesperplayer</th>\n",
       "      <th>Gametime</th>\n",
       "      <th>timepermove</th>\n",
       "      <th>my_kingcastle</th>\n",
       "      <th>my_queencastle</th>\n",
       "      <th>enemy_kingcastle</th>\n",
       "      <th>enemy_queencastle</th>\n",
       "      <th>my_moves_before_castle</th>\n",
       "      <th>enemy_moves_before_castle</th>\n",
       "      <th>no opens</th>\n",
       "      <th>Black c4 e5 Nc3 Nf6</th>\n",
       "      <th>Black d4 Nf6 Bf4 e6</th>\n",
       "      <th>Black d4 Nf6 Nf3 e6</th>\n",
       "      <th>Black d4 Nf6 c4 e6</th>\n",
       "      <th>Black d4 d5 Bf4 Nf6</th>\n",
       "      <th>Black d4 d5 c4 c6</th>\n",
       "      <th>Black e4 e5 Bc4 Nc6</th>\n",
       "      <th>Black e4 e5 Bc4 Nf6</th>\n",
       "      <th>Black e4 e5 Nc3 Nf6</th>\n",
       "      <th>Black e4 e5 Nf3 Nc6</th>\n",
       "      <th>Black e4 e5 Nf3 Nf6</th>\n",
       "      <th>Black e4 e5 d4 exd4</th>\n",
       "      <th>Black e4 e5 f4 d5</th>\n",
       "      <th>Black e4 e5 f4 exf4</th>\n",
       "      <th>Black e4 e6 Bc4 d5</th>\n",
       "      <th>Black e4 e6 Nc3 d5</th>\n",
       "      <th>Black e4 e6 Nf3 d5</th>\n",
       "      <th>Black e4 e6 d4 d5</th>\n",
       "      <th>Black e4 e6 e5 c5</th>\n",
       "      <th>Black g3 e5 Bg2 Nf6</th>\n",
       "      <th>White e4 c5 Nf3 Nc6</th>\n",
       "      <th>White e4 c5 Nf3 d6</th>\n",
       "      <th>White e4 c5 Nf3 e6</th>\n",
       "      <th>White e4 c6 Nf3 d5</th>\n",
       "      <th>White e4 c6 d4 d5</th>\n",
       "      <th>White e4 d5 Nf3 dxe4</th>\n",
       "      <th>White e4 d5 exd5 Nf6</th>\n",
       "      <th>White e4 d5 exd5 Qxd5</th>\n",
       "      <th>White e4 e5 Nc3 Nc6</th>\n",
       "      <th>White e4 e5 Nc3 Nf6</th>\n",
       "      <th>White e4 e5 Nc3 d6</th>\n",
       "      <th>White e4 e5 Nf3 Bc5</th>\n",
       "      <th>White e4 e5 Nf3 Nc6</th>\n",
       "      <th>White e4 e5 Nf3 Nf6</th>\n",
       "      <th>White e4 e5 Nf3 Qf6</th>\n",
       "      <th>White e4 e5 Nf3 d5</th>\n",
       "      <th>White e4 e5 Nf3 d6</th>\n",
       "      <th>White e4 e6 Nf3 d5</th>\n",
       "      <th>White e4 e6 d4 d5</th>\n",
       "      <th>White e4 g6 d4 Bg7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1790</td>\n",
       "      <td>1785</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1777</td>\n",
       "      <td>1783</td>\n",
       "      <td>-6</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "      <td>845.4</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_won  my_color  my_rank  enemy_rank  rank_difference  is_higher  \\\n",
       "0      0         1     1790        1785                5       True   \n",
       "1      2         0     1777        1783               -6      False   \n",
       "\n",
       "   movesperplayer  Gametime  timepermove  my_kingcastle  my_queencastle  \\\n",
       "0              62    1079.0         17.4              1               0   \n",
       "1              37     845.4         22.8              1               0   \n",
       "\n",
       "   enemy_kingcastle  enemy_queencastle  my_moves_before_castle  \\\n",
       "0                 1                  0                    0.10   \n",
       "1                 0                  1                    0.08   \n",
       "\n",
       "   enemy_moves_before_castle  no opens  Black c4 e5 Nc3 Nf6  \\\n",
       "0                       0.09     False                False   \n",
       "1                       0.10     False                False   \n",
       "\n",
       "   Black d4 Nf6 Bf4 e6  Black d4 Nf6 Nf3 e6  Black d4 Nf6 c4 e6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   Black d4 d5 Bf4 Nf6  Black d4 d5 c4 c6  Black e4 e5 Bc4 Nc6  \\\n",
       "0                False              False                False   \n",
       "1                False              False                False   \n",
       "\n",
       "   Black e4 e5 Bc4 Nf6  Black e4 e5 Nc3 Nf6  Black e4 e5 Nf3 Nc6  \\\n",
       "0                False                False                False   \n",
       "1                False                False                 True   \n",
       "\n",
       "   Black e4 e5 Nf3 Nf6  Black e4 e5 d4 exd4  Black e4 e5 f4 d5  \\\n",
       "0                False                False              False   \n",
       "1                False                False              False   \n",
       "\n",
       "   Black e4 e5 f4 exf4  Black e4 e6 Bc4 d5  Black e4 e6 Nc3 d5  \\\n",
       "0                False               False               False   \n",
       "1                False               False               False   \n",
       "\n",
       "   Black e4 e6 Nf3 d5  Black e4 e6 d4 d5  Black e4 e6 e5 c5  \\\n",
       "0               False              False              False   \n",
       "1               False              False              False   \n",
       "\n",
       "   Black g3 e5 Bg2 Nf6  White e4 c5 Nf3 Nc6  White e4 c5 Nf3 d6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   White e4 c5 Nf3 e6  White e4 c6 Nf3 d5  White e4 c6 d4 d5  \\\n",
       "0               False               False              False   \n",
       "1               False               False              False   \n",
       "\n",
       "   White e4 d5 Nf3 dxe4  White e4 d5 exd5 Nf6  White e4 d5 exd5 Qxd5  \\\n",
       "0                 False                 False                  False   \n",
       "1                 False                 False                  False   \n",
       "\n",
       "   White e4 e5 Nc3 Nc6  White e4 e5 Nc3 Nf6  White e4 e5 Nc3 d6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "\n",
       "   White e4 e5 Nf3 Bc5  White e4 e5 Nf3 Nc6  White e4 e5 Nf3 Nf6  \\\n",
       "0                False                 True                False   \n",
       "1                False                False                False   \n",
       "\n",
       "   White e4 e5 Nf3 Qf6  White e4 e5 Nf3 d5  White e4 e5 Nf3 d6  \\\n",
       "0                False               False               False   \n",
       "1                False               False               False   \n",
       "\n",
       "   White e4 e6 Nf3 d5  White e4 e6 d4 d5  White e4 g6 d4 Bg7  \n",
       "0               False              False               False  \n",
       "1               False              False               False  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapid.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "621b13e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blitz', 'classical', 'bullet', 'rapid'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.speed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eaedea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_modes = [blitz, classical, bullet, rapid, final_all]\n",
    "game_modes_fixed = []\n",
    "\n",
    "def fix_infinity():\n",
    "    for i in game_modes:\n",
    "        i = i[~i[\"timepermove\"].isin([np.inf, -np.inf])]\n",
    "        game_modes_fixed.append(i)\n",
    "    return game_modes_fixed\n",
    "\n",
    "all_fixed = fix_infinity()\n",
    "blitz, classical, bullet, rapid, final_all = all_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0be4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cb378e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni_won - 0 -> I lost, 1-Draw, 2-I_Won\\nis_higher -> is my rank higher than my enemy\\ntimepermove -> Gametime / movesperplayer\\nWhite_moves_before_castle -> amount of white moves before castle\\nno opens - no specyfic opening typed played by evilsainpl\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column definiton\n",
    "\"\"\"\n",
    "i_won - 0 -> I lost, 1-Draw, 2-I_Won\n",
    "is_higher -> is my rank higher than my enemy\n",
    "timepermove -> Gametime / movesperplayer\n",
    "White_moves_before_castle -> amount of white moves before castle\n",
    "no opens - no specyfic opening typed played by evilsainpl\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06fa92",
   "metadata": {},
   "source": [
    "# modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d7f5e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_won</th>\n",
       "      <th>my_color</th>\n",
       "      <th>my_rank</th>\n",
       "      <th>enemy_rank</th>\n",
       "      <th>rank_difference</th>\n",
       "      <th>is_higher</th>\n",
       "      <th>movesperplayer</th>\n",
       "      <th>Gametime</th>\n",
       "      <th>timepermove</th>\n",
       "      <th>my_kingcastle</th>\n",
       "      <th>my_queencastle</th>\n",
       "      <th>enemy_kingcastle</th>\n",
       "      <th>enemy_queencastle</th>\n",
       "      <th>my_moves_before_castle</th>\n",
       "      <th>enemy_moves_before_castle</th>\n",
       "      <th>no opens</th>\n",
       "      <th>Black c4 e5 Nc3 Nf6</th>\n",
       "      <th>Black d4 Nf6 Bf4 e6</th>\n",
       "      <th>Black d4 Nf6 Nf3 e6</th>\n",
       "      <th>Black d4 Nf6 c4 e6</th>\n",
       "      <th>Black d4 d5 Bf4 Nf6</th>\n",
       "      <th>Black d4 d5 c4 c6</th>\n",
       "      <th>Black e4 e5 Bc4 Nc6</th>\n",
       "      <th>Black e4 e5 Bc4 Nf6</th>\n",
       "      <th>Black e4 e5 Nc3 Nf6</th>\n",
       "      <th>Black e4 e5 Nf3 Nc6</th>\n",
       "      <th>Black e4 e5 Nf3 Nf6</th>\n",
       "      <th>Black e4 e5 d4 exd4</th>\n",
       "      <th>Black e4 e5 f4 d5</th>\n",
       "      <th>Black e4 e5 f4 exf4</th>\n",
       "      <th>Black e4 e6 Bc4 d5</th>\n",
       "      <th>Black e4 e6 Nc3 d5</th>\n",
       "      <th>Black e4 e6 Nf3 d5</th>\n",
       "      <th>Black e4 e6 d4 d5</th>\n",
       "      <th>Black e4 e6 e5 c5</th>\n",
       "      <th>Black g3 e5 Bg2 Nf6</th>\n",
       "      <th>White e4 c5 Nf3 Nc6</th>\n",
       "      <th>White e4 c5 Nf3 d6</th>\n",
       "      <th>White e4 c5 Nf3 e6</th>\n",
       "      <th>White e4 c6 Nf3 d5</th>\n",
       "      <th>White e4 c6 d4 d5</th>\n",
       "      <th>White e4 d5 Nf3 dxe4</th>\n",
       "      <th>White e4 d5 exd5 Nf6</th>\n",
       "      <th>White e4 d5 exd5 Qxd5</th>\n",
       "      <th>White e4 e5 Nc3 Nc6</th>\n",
       "      <th>White e4 e5 Nc3 Nf6</th>\n",
       "      <th>White e4 e5 Nc3 d6</th>\n",
       "      <th>White e4 e5 Nf3 Bc5</th>\n",
       "      <th>White e4 e5 Nf3 Nc6</th>\n",
       "      <th>White e4 e5 Nf3 Nf6</th>\n",
       "      <th>White e4 e5 Nf3 Qf6</th>\n",
       "      <th>White e4 e5 Nf3 d5</th>\n",
       "      <th>White e4 e5 Nf3 d6</th>\n",
       "      <th>White e4 e6 Nf3 d5</th>\n",
       "      <th>White e4 e6 d4 d5</th>\n",
       "      <th>White e4 g6 d4 Bg7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1753</td>\n",
       "      <td>1735</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>617.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1758</td>\n",
       "      <td>1801</td>\n",
       "      <td>-43</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>105.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1764</td>\n",
       "      <td>1790</td>\n",
       "      <td>-26</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>173.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1771</td>\n",
       "      <td>1738</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1778</td>\n",
       "      <td>1760</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>180.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_won  my_color  my_rank  enemy_rank  rank_difference  is_higher  \\\n",
       "0      2         1     1753        1735               18       True   \n",
       "1      0         0     1758        1801              -43      False   \n",
       "2      0         0     1764        1790              -26      False   \n",
       "3      0         1     1771        1738               33       True   \n",
       "4      0         0     1778        1760               18       True   \n",
       "\n",
       "   movesperplayer  Gametime  timepermove  my_kingcastle  my_queencastle  \\\n",
       "0              70     617.0          8.8              1               0   \n",
       "1              18     105.1          5.8              0               1   \n",
       "2              15     173.9         11.6              0               0   \n",
       "3              12      47.0          3.9              1               0   \n",
       "4              19     180.4          9.5              1               0   \n",
       "\n",
       "   enemy_kingcastle  enemy_queencastle  my_moves_before_castle  \\\n",
       "0                 0                  0                    0.06   \n",
       "1                 1                  0                    0.14   \n",
       "2                 0                  1                    1.00   \n",
       "3                 1                  0                    0.05   \n",
       "4                 1                  0                    0.06   \n",
       "\n",
       "   enemy_moves_before_castle  no opens  Black c4 e5 Nc3 Nf6  \\\n",
       "0                       1.00     False                False   \n",
       "1                       0.17      True                False   \n",
       "2                       0.12     False                False   \n",
       "3                       0.09     False                False   \n",
       "4                       0.06     False                False   \n",
       "\n",
       "   Black d4 Nf6 Bf4 e6  Black d4 Nf6 Nf3 e6  Black d4 Nf6 c4 e6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "2                False                False               False   \n",
       "3                False                False               False   \n",
       "4                False                False               False   \n",
       "\n",
       "   Black d4 d5 Bf4 Nf6  Black d4 d5 c4 c6  Black e4 e5 Bc4 Nc6  \\\n",
       "0                False              False                False   \n",
       "1                False              False                False   \n",
       "2                False              False                False   \n",
       "3                False              False                False   \n",
       "4                False              False                False   \n",
       "\n",
       "   Black e4 e5 Bc4 Nf6  Black e4 e5 Nc3 Nf6  Black e4 e5 Nf3 Nc6  \\\n",
       "0                False                False                False   \n",
       "1                False                False                False   \n",
       "2                False                 True                False   \n",
       "3                False                False                False   \n",
       "4                False                False                 True   \n",
       "\n",
       "   Black e4 e5 Nf3 Nf6  Black e4 e5 d4 exd4  Black e4 e5 f4 d5  \\\n",
       "0                False                False              False   \n",
       "1                False                False              False   \n",
       "2                False                False              False   \n",
       "3                False                False              False   \n",
       "4                False                False              False   \n",
       "\n",
       "   Black e4 e5 f4 exf4  Black e4 e6 Bc4 d5  Black e4 e6 Nc3 d5  \\\n",
       "0                False               False               False   \n",
       "1                False               False               False   \n",
       "2                False               False               False   \n",
       "3                False               False               False   \n",
       "4                False               False               False   \n",
       "\n",
       "   Black e4 e6 Nf3 d5  Black e4 e6 d4 d5  Black e4 e6 e5 c5  \\\n",
       "0               False              False              False   \n",
       "1               False              False              False   \n",
       "2               False              False              False   \n",
       "3               False              False              False   \n",
       "4               False              False              False   \n",
       "\n",
       "   Black g3 e5 Bg2 Nf6  White e4 c5 Nf3 Nc6  White e4 c5 Nf3 d6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "2                False                False               False   \n",
       "3                False                False               False   \n",
       "4                False                False               False   \n",
       "\n",
       "   White e4 c5 Nf3 e6  White e4 c6 Nf3 d5  White e4 c6 d4 d5  \\\n",
       "0               False               False              False   \n",
       "1               False               False              False   \n",
       "2               False               False              False   \n",
       "3               False               False              False   \n",
       "4               False               False              False   \n",
       "\n",
       "   White e4 d5 Nf3 dxe4  White e4 d5 exd5 Nf6  White e4 d5 exd5 Qxd5  \\\n",
       "0                 False                 False                  False   \n",
       "1                 False                 False                  False   \n",
       "2                 False                 False                  False   \n",
       "3                 False                 False                  False   \n",
       "4                 False                 False                  False   \n",
       "\n",
       "   White e4 e5 Nc3 Nc6  White e4 e5 Nc3 Nf6  White e4 e5 Nc3 d6  \\\n",
       "0                False                False               False   \n",
       "1                False                False               False   \n",
       "2                False                False               False   \n",
       "3                False                False               False   \n",
       "4                False                False               False   \n",
       "\n",
       "   White e4 e5 Nf3 Bc5  White e4 e5 Nf3 Nc6  White e4 e5 Nf3 Nf6  \\\n",
       "0                False                 True                False   \n",
       "1                False                False                False   \n",
       "2                False                False                False   \n",
       "3                False                False                False   \n",
       "4                False                False                False   \n",
       "\n",
       "   White e4 e5 Nf3 Qf6  White e4 e5 Nf3 d5  White e4 e5 Nf3 d6  \\\n",
       "0                False               False               False   \n",
       "1                False               False               False   \n",
       "2                False               False               False   \n",
       "3                False               False               False   \n",
       "4                False               False               False   \n",
       "\n",
       "   White e4 e6 Nf3 d5  White e4 e6 d4 d5  White e4 g6 d4 Bg7  \n",
       "0               False              False               False  \n",
       "1               False              False               False  \n",
       "2               False              False               False  \n",
       "3               False              False                True  \n",
       "4               False              False               False  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blitz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b893346",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([blitz, bullet])\n",
    "Test = pd.concat([rapid, classical])\n",
    "\n",
    "X = Train.drop(\"i_won\", axis=1)\n",
    "y = Train[\"i_won\"]\n",
    "\n",
    "X_F = Test.drop([\"i_won\"], axis=1)\n",
    "y_F = Test[\"i_won\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61079f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import tree, ensemble, naive_bayes, neighbors, semi_supervised, discriminant_analysis, svm, linear_model, neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e98f0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_models_test(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Function to test some classifiers, without any parameters\n",
    "    \"\"\"\n",
    "    models=[\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    semi_supervised.LabelPropagation(),\n",
    "    semi_supervised.LabelSpreading(),\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    svm.LinearSVC(multi_class=\"crammer_singer\"),\n",
    "    linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000),\n",
    "    linear_model.LogisticRegressionCV(multi_class=\"multinomial\", max_iter=1000),\n",
    "    neural_network.MLPClassifier(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    linear_model.RidgeClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    ]\n",
    "    result = dict()\n",
    "    results2 = dict()\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred2 = model.predict(X_F)\n",
    "        result[str(model)]= f\"f1_score: {round(f1_score(y_test, y_pred, average='weighted'), 4)}, precision_score: {round(precision_score(y_test, y_pred, average='weighted'), 4)}, accuracy_score: {round(accuracy_score(y_test, y_pred), 4)}\"\n",
    "        results2[str(model)]=f\"TEST SCORE:f1_score: {round(f1_score(y_F, y_pred2, average='weighted'), 4)}, precision_score: {round(precision_score(y_F, y_pred2, average='weighted'), 4)}, accuracy_score: {round(accuracy_score(y_F, y_pred2), 4)}\"\n",
    "        \n",
    "        \n",
    "    return result, results2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2035b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, X, y, X_test_F, y_test_F, n=5):\n",
    "    \"\"\" model <- model to test,\n",
    "        X, y <- X, y to train and test\n",
    "        X_test. y_test <- diff data for testing only\n",
    "        n <- num. of folds\n",
    "    \"\"\"\n",
    "    Train_res = list()\n",
    "    Test_res = list()\n",
    "    Final_test = list()\n",
    "    AVG = dict()\n",
    "    \n",
    "    for i in range(n):\n",
    "        test_model = model\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = i)\n",
    "        test_model.fit(X_train, y_train)\n",
    "        y_pred_test = test_model.predict(X_test)\n",
    "        y_pred_train = test_model.predict(X_train)\n",
    "        Train_res.append(f1_score(y_train, y_pred_train, average='weighted'))\n",
    "        Test_res.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
    "    test_model = model\n",
    "    test_model.fit(X, y)\n",
    "    y_pred_F = test_model.predict(X_test_F)\n",
    "    Final_test.append(f1_score(y_test_F, y_pred_F, average='weighted'))   \n",
    "        \n",
    "    AVG[\"Train\"]=sum(Train_res)/n\n",
    "    AVG[\"Test\"]=sum(Test_res)/n\n",
    "    AVG[\"Test_Final\"]=sum(Final_test)\n",
    "    return AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7a7dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    \"\"\"\n",
    "    y_true -> true value of predicted values\n",
    "    y_pred -> value estimated by model\n",
    "    classes -> names of predicted classes\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.xticks(tick_marks + 0.5, classes)\n",
    "    plt.yticks(tick_marks + 0.5, classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9cabcbed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'BernoulliNB()': 'f1_score: 0.5052, precision_score: 0.4931, accuracy_score: 0.5178',\n",
       "  'DecisionTreeClassifier()': 'f1_score: 0.4987, precision_score: 0.4988, accuracy_score: 0.4986',\n",
       "  'ExtraTreeClassifier()': 'f1_score: 0.488, precision_score: 0.4876, accuracy_score: 0.4886',\n",
       "  'ExtraTreesClassifier()': 'f1_score: 0.5295, precision_score: 0.5369, accuracy_score: 0.5369',\n",
       "  'GaussianNB()': 'f1_score: 0.1349, precision_score: 0.4848, accuracy_score: 0.1194',\n",
       "  'LabelPropagation()': 'f1_score: 0.2933, precision_score: 0.705, accuracy_score: 0.4603',\n",
       "  'LabelSpreading()': 'f1_score: 0.2933, precision_score: 0.705, accuracy_score: 0.4603',\n",
       "  'LinearDiscriminantAnalysis()': 'f1_score: 0.5454, precision_score: 0.549, accuracy_score: 0.5479',\n",
       "  \"LinearSVC(multi_class='crammer_singer')\": 'f1_score: 0.3278, precision_score: 0.245, accuracy_score: 0.495',\n",
       "  \"LogisticRegression(max_iter=1000, multi_class='multinomial')\": 'f1_score: 0.5238, precision_score: 0.53, accuracy_score: 0.5378',\n",
       "  \"LogisticRegressionCV(max_iter=1000, multi_class='multinomial')\": 'f1_score: 0.5505, precision_score: 0.5575, accuracy_score: 0.5661',\n",
       "  'MLPClassifier()': 'f1_score: 0.4563, precision_score: 0.5492, accuracy_score: 0.4813',\n",
       "  'QuadraticDiscriminantAnalysis()': 'f1_score: 0.0671, precision_score: 0.4745, accuracy_score: 0.0793',\n",
       "  'RandomForestClassifier()': 'f1_score: 0.5215, precision_score: 0.5252, accuracy_score: 0.5342',\n",
       "  'RidgeClassifier()': 'f1_score: 0.5438, precision_score: 0.5812, accuracy_score: 0.5597',\n",
       "  'RidgeClassifierCV()': 'f1_score: 0.5435, precision_score: 0.5813, accuracy_score: 0.5597'},\n",
       " {'BernoulliNB()': 'TEST SCORE:f1_score: 0.5041, precision_score: 0.4981, accuracy_score: 0.5123',\n",
       "  'DecisionTreeClassifier()': 'TEST SCORE:f1_score: 0.5162, precision_score: 0.5206, accuracy_score: 0.5143',\n",
       "  'ExtraTreeClassifier()': 'TEST SCORE:f1_score: 0.492, precision_score: 0.494, accuracy_score: 0.4918',\n",
       "  'ExtraTreesClassifier()': 'TEST SCORE:f1_score: 0.5059, precision_score: 0.4995, accuracy_score: 0.5143',\n",
       "  'GaussianNB()': 'TEST SCORE:f1_score: 0.1794, precision_score: 0.5162, accuracy_score: 0.1393',\n",
       "  'LabelPropagation()': 'TEST SCORE:f1_score: 0.2444, precision_score: 0.173, accuracy_score: 0.416',\n",
       "  'LabelSpreading()': 'TEST SCORE:f1_score: 0.2444, precision_score: 0.173, accuracy_score: 0.416',\n",
       "  'LinearDiscriminantAnalysis()': 'TEST SCORE:f1_score: 0.554, precision_score: 0.5494, accuracy_score: 0.5615',\n",
       "  \"LinearSVC(multi_class='crammer_singer')\": 'TEST SCORE:f1_score: 0.3928, precision_score: 0.5752, accuracy_score: 0.5471',\n",
       "  \"LogisticRegression(max_iter=1000, multi_class='multinomial')\": 'TEST SCORE:f1_score: 0.5464, precision_score: 0.5378, accuracy_score: 0.5553',\n",
       "  \"LogisticRegressionCV(max_iter=1000, multi_class='multinomial')\": 'TEST SCORE:f1_score: 0.5485, precision_score: 0.5387, accuracy_score: 0.5594',\n",
       "  'MLPClassifier()': 'TEST SCORE:f1_score: 0.4539, precision_score: 0.464, accuracy_score: 0.4898',\n",
       "  'QuadraticDiscriminantAnalysis()': 'TEST SCORE:f1_score: 0.0878, precision_score: 0.4363, accuracy_score: 0.084',\n",
       "  'RandomForestClassifier()': 'TEST SCORE:f1_score: 0.5553, precision_score: 0.5458, accuracy_score: 0.5656',\n",
       "  'RidgeClassifier()': 'TEST SCORE:f1_score: 0.5471, precision_score: 0.5357, accuracy_score: 0.5594',\n",
       "  'RidgeClassifierCV()': 'TEST SCORE:f1_score: 0.5548, precision_score: 0.5433, accuracy_score: 0.5676'})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_models_test(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e3f8658d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i_won\n",
       "2    0.500912\n",
       "0    0.454400\n",
       "1    0.044688\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()/y.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "60fb9730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i_won\n",
       "2    0.545082\n",
       "0    0.415984\n",
       "1    0.038934\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_F.value_counts()/y_F.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc2a216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3fe75f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=300)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_params = {'max_depth': 5,\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 300}\n",
    "RF = ensemble.RandomForestClassifier(**RandomForest_params)\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "11b19791",
   "metadata": {},
   "outputs": [],
   "source": [
    "FE = pd.DataFrame(index = X.columns, data=RF.feature_importances_, columns=[\"wano\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cc87b8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Black e4 e5 Nc3 Nf6</th>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black c4 e5 Nc3 Nf6</th>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nf3 Qf6</th>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 d5 Nf3 dxe4</th>\n",
       "      <td>0.001123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e6 Nf3 d5</th>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black d4 d5 Bf4 Nf6</th>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black g3 e5 Bg2 Nf6</th>\n",
       "      <td>0.001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e6 Bc4 d5</th>\n",
       "      <td>0.001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e5 Bc4 Nf6</th>\n",
       "      <td>0.001527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e5 f4 d5</th>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e6 e5 c5</th>\n",
       "      <td>0.001780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nf3 d5</th>\n",
       "      <td>0.001926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nc3 d6</th>\n",
       "      <td>0.001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 g6 d4 Bg7</th>\n",
       "      <td>0.002299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e5 d4 exd4</th>\n",
       "      <td>0.002543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nf3 Nf6</th>\n",
       "      <td>0.002671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e5 Nf3 Nf6</th>\n",
       "      <td>0.002753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 c6 d4 d5</th>\n",
       "      <td>0.002861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e6 d4 d5</th>\n",
       "      <td>0.002866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nc3 Nf6</th>\n",
       "      <td>0.002879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 c6 Nf3 d5</th>\n",
       "      <td>0.002997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black d4 Nf6 Nf3 e6</th>\n",
       "      <td>0.002998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nf3 d6</th>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e6 d4 d5</th>\n",
       "      <td>0.003292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 c5 Nf3 d6</th>\n",
       "      <td>0.003351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nc3 Nc6</th>\n",
       "      <td>0.003922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 d5 exd5 Nf6</th>\n",
       "      <td>0.004026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_queencastle</th>\n",
       "      <td>0.004231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nf3 Nc6</th>\n",
       "      <td>0.004420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black d4 d5 c4 c6</th>\n",
       "      <td>0.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 d5 exd5 Qxd5</th>\n",
       "      <td>0.004549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e6 Nf3 d5</th>\n",
       "      <td>0.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no opens</th>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 c5 Nf3 Nc6</th>\n",
       "      <td>0.004753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black d4 Nf6 Bf4 e6</th>\n",
       "      <td>0.004780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e5 f4 exf4</th>\n",
       "      <td>0.004804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 e5 Nf3 Bc5</th>\n",
       "      <td>0.004826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e6 Nc3 d5</th>\n",
       "      <td>0.004879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e5 Bc4 Nc6</th>\n",
       "      <td>0.005247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black e4 e5 Nf3 Nc6</th>\n",
       "      <td>0.005469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_queencastle</th>\n",
       "      <td>0.005634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_kingcastle</th>\n",
       "      <td>0.007944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_color</th>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black d4 Nf6 c4 e6</th>\n",
       "      <td>0.019117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White e4 c5 Nf3 e6</th>\n",
       "      <td>0.020218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_kingcastle</th>\n",
       "      <td>0.026671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_moves_before_castle</th>\n",
       "      <td>0.052341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_higher</th>\n",
       "      <td>0.052877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_moves_before_castle</th>\n",
       "      <td>0.055277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_rank</th>\n",
       "      <td>0.064468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timepermove</th>\n",
       "      <td>0.064697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_rank</th>\n",
       "      <td>0.097355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movesperplayer</th>\n",
       "      <td>0.194927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_difference</th>\n",
       "      <td>0.207341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            wano\n",
       "Black e4 e5 Nc3 Nf6        0.000562\n",
       "Black c4 e5 Nc3 Nf6        0.000841\n",
       "White e4 e5 Nf3 Qf6        0.001005\n",
       "White e4 d5 Nf3 dxe4       0.001123\n",
       "White e4 e6 Nf3 d5         0.001143\n",
       "Black d4 d5 Bf4 Nf6        0.001230\n",
       "Black g3 e5 Bg2 Nf6        0.001329\n",
       "Black e4 e6 Bc4 d5         0.001518\n",
       "Black e4 e5 Bc4 Nf6        0.001527\n",
       "Black e4 e5 f4 d5          0.001756\n",
       "Black e4 e6 e5 c5          0.001780\n",
       "White e4 e5 Nf3 d5         0.001926\n",
       "White e4 e5 Nc3 d6         0.001937\n",
       "White e4 g6 d4 Bg7         0.002299\n",
       "Black e4 e5 d4 exd4        0.002543\n",
       "White e4 e5 Nf3 Nf6        0.002671\n",
       "Black e4 e5 Nf3 Nf6        0.002753\n",
       "White e4 c6 d4 d5          0.002861\n",
       "White e4 e6 d4 d5          0.002866\n",
       "White e4 e5 Nc3 Nf6        0.002879\n",
       "White e4 c6 Nf3 d5         0.002997\n",
       "Black d4 Nf6 Nf3 e6        0.002998\n",
       "White e4 e5 Nf3 d6         0.003151\n",
       "Black e4 e6 d4 d5          0.003292\n",
       "White e4 c5 Nf3 d6         0.003351\n",
       "White e4 e5 Nc3 Nc6        0.003922\n",
       "White e4 d5 exd5 Nf6       0.004026\n",
       "my_queencastle             0.004231\n",
       "White e4 e5 Nf3 Nc6        0.004420\n",
       "Black d4 d5 c4 c6          0.004456\n",
       "White e4 d5 exd5 Qxd5      0.004549\n",
       "Black e4 e6 Nf3 d5         0.004566\n",
       "no opens                   0.004701\n",
       "White e4 c5 Nf3 Nc6        0.004753\n",
       "Black d4 Nf6 Bf4 e6        0.004780\n",
       "Black e4 e5 f4 exf4        0.004804\n",
       "White e4 e5 Nf3 Bc5        0.004826\n",
       "Black e4 e6 Nc3 d5         0.004879\n",
       "Black e4 e5 Bc4 Nc6        0.005247\n",
       "Black e4 e5 Nf3 Nc6        0.005469\n",
       "enemy_queencastle          0.005634\n",
       "enemy_kingcastle           0.007944\n",
       "my_color                   0.009168\n",
       "Black d4 Nf6 c4 e6         0.019117\n",
       "White e4 c5 Nf3 e6         0.020218\n",
       "my_kingcastle              0.026671\n",
       "enemy_moves_before_castle  0.052341\n",
       "is_higher                  0.052877\n",
       "my_moves_before_castle     0.055277\n",
       "my_rank                    0.064468\n",
       "timepermove                0.064697\n",
       "enemy_rank                 0.097355\n",
       "movesperplayer             0.194927\n",
       "rank_difference            0.207341"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.sort_values(\"wano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b8824981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABQCUlEQVR4nO3dd3gU5frG8XuTkE1ITyghSA0QQhdQREqCIE2awSNFFJDmEUWJgKIizUNQpNixAlIOVvCICkgJiAYOJUgRgUSKdAglJEASkvn9wWF/LkNJIMsu7PfjtdfFvjM78+yaizzc7zuzFsMwDAEAAAB/4+HsAgAAAOB6aBIBAABgQpMIAAAAE5pEAAAAmNAkAgAAwIQmEQAAACY0iQAAADChSQQAAIAJTSIAAABMaBIBXNXOnTvVsmVLBQUFyWKxaP78+YV6/N27d8tisWj69OmFetxbWWxsrGJjY51dBgA3R5MI3AJSU1M1YMAAVaxYUT4+PgoMDFSjRo305ptv6uzZsw49d8+ePbV582b961//0syZM1W/fn2Hnu9m6tWrlywWiwIDAy/7Oe7cuVMWi0UWi0VvvPFGgY9/4MABjRo1Shs3biyEagHg5vJydgEAru7777/XP/7xD1mtVj322GOqUaOGsrOztWrVKg0dOlRbt27Vhx9+6JBznz17VklJSXrppZf01FNPOeQc5cqV09mzZ1WkSBGHHP9avLy8dObMGX333Xd6+OGH7bbNnj1bPj4+Onfu3HUd+8CBAxo9erTKly+vOnXq5Pt1ixcvvq7zAUBhokkEXNiuXbvUtWtXlStXTsuWLVOpUqVs2wYOHKiUlBR9//33Djv/0aNHJUnBwcEOO4fFYpGPj4/Djn8tVqtVjRo10r///W9Tkzhnzhw98MAD+vrrr29KLWfOnFHRokXl7e19U84HAFfDdDPgwl5//XVlZGTok08+sWsQL6pUqZKeeeYZ2/Pz589r7NixioyMlNVqVfny5fXiiy8qKyvL7nXly5dXu3bttGrVKt19993y8fFRxYoV9dlnn9n2GTVqlMqVKydJGjp0qCwWi8qXLy/pwjTtxT//3ahRo2SxWOzGfvrpJzVu3FjBwcHy9/dXVFSUXnzxRdv2K61JXLZsmZo0aSI/Pz8FBwerY8eO2rZt22XPl5KSol69eik4OFhBQUHq3bu3zpw5c+UP9hLdu3fXjz/+qJMnT9rG1q5dq507d6p79+6m/Y8fP64hQ4aoZs2a8vf3V2BgoNq0aaPffvvNtk9iYqLuuusuSVLv3r1t09YX32dsbKxq1Kih9evXq2nTpipatKjtc7l0TWLPnj3l4+Njev+tWrVSSEiIDhw4kO/3CgD5RZMIuLDvvvtOFStW1L333puv/fv27atXXnlFdevW1eTJkxUTE6OEhAR17drVtG9KSooeeugh3X///Zo4caJCQkLUq1cvbd26VZIUFxenyZMnS5K6deummTNnasqUKQWqf+vWrWrXrp2ysrI0ZswYTZw4UR06dNAvv/xy1dctWbJErVq10pEjRzRq1CjFx8fr119/VaNGjbR7927T/g8//LBOnz6thIQEPfzww5o+fbpGjx6d7zrj4uJksVj0zTff2MbmzJmjqlWrqm7duqb9//zzT82fP1/t2rXTpEmTNHToUG3evFkxMTG2hi06OlpjxoyRJPXv318zZ87UzJkz1bRpU9tx0tLS1KZNG9WpU0dTpkxRs2bNLlvfm2++qeLFi6tnz57Kzc2VJH3wwQdavHix3n77bUVEROT7vQJAvhkAXNKpU6cMSUbHjh3ztf/GjRsNSUbfvn3txocMGWJIMpYtW2YbK1eunCHJWLlypW3syJEjhtVqNZ577jnb2K5duwxJxoQJE+yO2bNnT6NcuXKmGkaOHGn8/a+VyZMnG5KMo0ePXrHui+eYNm2abaxOnTpGiRIljLS0NNvYb7/9Znh4eBiPPfaY6XyPP/643TEffPBBIyws7Irn/Pv78PPzMwzDMB566CGjefPmhmEYRm5urhEeHm6MHj36sp/BuXPnjNzcXNP7sFqtxpgxY2xja9euNb23i2JiYgxJxtSpUy+7LSYmxm5s0aJFhiTj1VdfNf7880/D39/f6NSp0zXfIwBcL5JEwEWlp6dLkgICAvK1/w8//CBJio+Ptxt/7rnnJMm0drFatWpq0qSJ7Xnx4sUVFRWlP//887prvtTFtYzffvut8vLy8vWagwcPauPGjerVq5dCQ0Nt47Vq1dL9999ve59/98QTT9g9b9KkidLS0myfYX50795diYmJOnTokJYtW6ZDhw5ddqpZurCO0cPjwl+fubm5SktLs02lb9iwId/ntFqt6t27d772bdmypQYMGKAxY8YoLi5OPj4++uCDD/J9LgAoKJpEwEUFBgZKkk6fPp2v/ffs2SMPDw9VqlTJbjw8PFzBwcHas2eP3XjZsmVNxwgJCdGJEyeus2KzLl26qFGjRurbt69Kliyprl276osvvrhqw3ixzqioKNO26OhoHTt2TJmZmXbjl76XkJAQSSrQe2nbtq0CAgL0+eefa/bs2brrrrtMn+VFeXl5mjx5sipXriyr1apixYqpePHi2rRpk06dOpXvc5YuXbpAF6m88cYbCg0N1caNG/XWW2+pRIkS+X4tABQUTSLgogIDAxUREaEtW7YU6HWXXjhyJZ6enpcdNwzjus9xcb3cRb6+vlq5cqWWLFmiRx99VJs2bVKXLl10//33m/a9ETfyXi6yWq2Ki4vTjBkzNG/evCumiJI0btw4xcfHq2nTppo1a5YWLVqkn376SdWrV893Yipd+HwKIjk5WUeOHJEkbd68uUCvBYCCokkEXFi7du2UmpqqpKSka+5brlw55eXlaefOnXbjhw8f1smTJ21XKheGkJAQuyuBL7o0rZQkDw8PNW/eXJMmTdLvv/+uf/3rX1q2bJmWL19+2WNfrHP79u2mbX/88YeKFSsmPz+/G3sDV9C9e3clJyfr9OnTl73Y56KvvvpKzZo10yeffKKuXbuqZcuWatGihekzyW/Dnh+ZmZnq3bu3qlWrpv79++v111/X2rVrC+34AHApmkTAhQ0bNkx+fn7q27evDh8+bNqempqqN998U9KF6VJJpiuQJ02aJEl64IEHCq2uyMhInTp1Sps2bbKNHTx4UPPmzbPb7/jx46bXXryp9KW35bmoVKlSqlOnjmbMmGHXdG3ZskWLFy+2vU9HaNasmcaOHat33nlH4eHhV9zP09PTlFJ++eWX2r9/v93YxWb2cg11QT3//PPau3evZsyYoUmTJql8+fLq2bPnFT9HALhR3EwbcGGRkZGaM2eOunTpoujoaLtvXPn111/15ZdfqlevXpKk2rVrq2fPnvrwww918uRJxcTE6L///a9mzJihTp06XfH2Kteja9euev755/Xggw9q0KBBOnPmjN5//31VqVLF7sKNMWPGaOXKlXrggQdUrlw5HTlyRO+9957uuOMONW7c+IrHnzBhgtq0aaOGDRuqT58+Onv2rN5++20FBQVp1KhRhfY+LuXh4aGXX375mvu1a9dOY8aMUe/evXXvvfdq8+bNmj17tipWrGi3X2RkpIKDgzV16lQFBATIz89PDRo0UIUKFQpU17Jly/Tee+9p5MiRtlvyTJs2TbGxsRoxYoRef/31Ah0PAPLFyVdXA8iHHTt2GP369TPKly9veHt7GwEBAUajRo2Mt99+2zh37pxtv5ycHGP06NFGhQoVjCJFihhlypQxhg8fbrePYVy4Bc4DDzxgOs+lt1650i1wDMMwFi9ebNSoUcPw9vY2oqKijFmzZplugbN06VKjY8eORkREhOHt7W1EREQY3bp1M3bs2GE6x6W3iVmyZInRqFEjw9fX1wgMDDTat29v/P7773b7XDzfpbfYmTZtmiHJ2LVr1xU/U8OwvwXOlVzpFjjPPfecUapUKcPX19do1KiRkZSUdNlb13z77bdGtWrVDC8vL7v3GRMTY1SvXv2y5/z7cdLT041y5coZdevWNXJycuz2Gzx4sOHh4WEkJSVd9T0AwPWwGEYBVnYDAADALbAmEQAAACY0iQAAADChSQQAAIAJTSIAAABMaBIBAABgQpMIAAAAE5pEAAAAmNyW37gyaP4fzi4BMHm9XVVnlwDY6Tp9nbNLAOzM71vfaef2vfMphx37bPI7Dju2I5EkAgAAwOS2TBIBAAAKxEJudimaRAAAAIvF2RW4HNpmAAAAmJAkAgAAMN1swicCAAAAE5JEAAAA1iSakCQCAADAhCQRAACANYkmfCIAAAAwIUkEAABgTaIJTSIAAADTzSZ8IgAAADAhSQQAAGC62YQkEQAAACYkiQAAAKxJNOETAQAAgAlJIgAAAGsSTUgSAQAAYEKSCAAAwJpEE5pEAAAApptNaJsBAABgQpIIAADAdLMJnwgAAABMSBIBAABIEk34RAAAAGBCkggAAODB1c2XIkkEAABwIStXrlT79u0VEREhi8Wi+fPn2223WCyXfUyYMMG2T/ny5U3bx48fX6A6SBIBAABcaE1iZmamateurccff1xxcXGm7QcPHrR7/uOPP6pPnz7q3Lmz3fiYMWPUr18/2/OAgIAC1UGTCAAA4EI3027Tpo3atGlzxe3h4eF2z7/99ls1a9ZMFStWtBsPCAgw7VsQrtM2AwAA3IaysrKUnp5u98jKyiqUYx8+fFjff/+9+vTpY9o2fvx4hYWF6c4779SECRN0/vz5Ah2bJhEAAMDi4bBHQkKCgoKC7B4JCQmFUvaMGTMUEBBgmpYeNGiQ5s6dq+XLl2vAgAEaN26chg0bVqBjM90MAADgQMOHD1d8fLzdmNVqLZRjf/rpp3rkkUfk4+NjN/7389WqVUve3t4aMGCAEhIS8n1umkQAAAAHrkm0Wq2F1hT+3c8//6zt27fr888/v+a+DRo00Pnz57V7925FRUXl6/hMNwMAANyCPvnkE9WrV0+1a9e+5r4bN26Uh4eHSpQoke/jkyQCAAC40C1wMjIylJKSYnu+a9cubdy4UaGhoSpbtqwkKT09XV9++aUmTpxoen1SUpLWrFmjZs2aKSAgQElJSRo8eLB69OihkJCQfNdBkwgAAOBC1q1bp2bNmtmeX1xf2LNnT02fPl2SNHfuXBmGoW7dupleb7VaNXfuXI0aNUpZWVmqUKGCBg8ebFoXeS00iQAAAC50n8TY2FgZhnHVffr376/+/ftfdlvdunW1evXqG66DJhEAAMCFpptdBZ8IAAAATEgSAQAAXGi62VWQJAIAAMCEJBEAAIA1iSZ8IgAAADAhSQQAAGBNoglJIgAAAExIEgEAAFiTaEKTCAAAQJNowicCAAAAE5JEAAAALlwxIUkEAACACUkiAAAAaxJN+EQAAABgQpIIAADAmkQTkkQAAACYkCQCAACwJtGEJhEAAIDpZhPaZgAAAJiQJAIAALdnIUk0IUkEAACACUkiAABweySJZiSJAAAAMCFJBAAAIEg0IUkEAACACUkiAABwe6xJNHOpJDElJUWLFi3S2bNnJUmGYTi5IgAA4A4sFovDHrcql2gS09LS1KJFC1WpUkVt27bVwYMHJUl9+vTRc8895+TqAAAA3I9LNImDBw+Wl5eX9u7dq6JFi9rGu3TpooULFzqxMgAA4A5IEs1cYk3i4sWLtWjRIt1xxx1245UrV9aePXucVBUAAID7cokmMTMz0y5BvOj48eOyWq1OqAgAALiTWznxcxSXaBKbNGmizz77TGPHjpV04X9UXl6eXn/9dTVr1szJ1d3+rF4eeiC6mGqVCpC/1VP7T57T15uPaO/Jc5KkNlWLqW7pAAX7FlFunqG/Tp7Tgm1HtefEOSdXDnczd85szZj2iY4dO6oqUVX1wosjVLNWLWeXhdtQtXB/PVgrXJFhRRXq562En1K0Zs9J2/Z7ygerddXiqljMT4E+Xhr8zVbtOn7W7hhFPC3q3aCMGlcMVRFPizbuS9fUX/fo1NnzN/ndANfHJdYkvv766/rwww/Vpk0bZWdna9iwYapRo4ZWrlyp1157zdnl3fa61QlXVHE/zVx/QOOX7dIfR89oYKMyCvK58G+IIxnZ+nLTYY1ftktTft6j42dy9OS9ZeTv7enkyuFOFv74g954PUEDnhyouV/OU1RUVf1zQB+lpaU5uzTchny8PLQr7Yw++HXvFbf/fjhDn63dd8VjPH5PGd1VNkgTlqbq5QXbFVK0iF5oUclRJeNGWRz4uEW5RJNYo0YN7dixQ40bN1bHjh2VmZmpuLg4JScnKzIy0tnl3daKeFhUOyJA3249otS0szqWmaMf/zimY5k5alwhWJK0fl+6dhw9o7QzOTp0OlvzthyRbxFPRQSyFAA3z8wZ0xT30MPq9GBnRVaqpJdHjpaPj4/mf/O1s0vDbWjDvnTNWX/ALj38u8SU4/oi+aA27U+/7PaiRTzVokoxfbp6nzYfPK3UtDN6e+VuRZf0V5Xifg6sHCg8LjHdLElBQUF66aWXnF2G2/HwsMjTw6Lzufb3pMzOzVPFMPM6UU+LdG/5YJ3JydX+9KybVSbcXE52trb9vlV9+g2wjXl4eOiee+7Vpt+SnVgZcHmRxYqqiKeHNh34/yZy/6lzOnI6S1El/bXjaKYTq8PlsCbRzCWSxIULF2rVqlW25++++67q1Kmj7t2768SJE06s7PaXdT5Pu9LOqFXVYgr08ZJFUv07AlUh1FeB1v+fTq5e0k8T2lXRxA5Rio0M0Xu//KXM7FznFQ63cuLkCeXm5iosLMxuPCwsTMeOHXNSVcCVhRQtopzcPNPfkyfPnleIr8vkM8BVuUSTOHToUKWnX/jX1ubNmxUfH6+2bdtq165dio+Pv+prs7KylJ6ebvfIzcm+GWXfNmauPyiLpFdbV9KkDlGKiQzR+n3p+nu2uPPYGb22fJemrNyjbUcy1fuuCNYkAgBuG9wn0cwlmsRdu3apWrVqkqSvv/5a7du317hx4/Tuu+/qxx9/vOprExISFBQUZPdY9/WHN6Ps28axMzl6a9VeDfluu0YuStHEFXvkabEoLTPHtk92rqFjmTnafeKc/p18SLmG1LBckBOrhjsJCQ6Rp6en6SKVtLQ0FStWzElVAVd24kyOinh6yO+Sf0wH+3rpBFc3uySaRDOXaBK9vb115swZSdKSJUvUsmVLSVJoaKgtYbyS4cOH69SpU3aP+p37O7zm21F2rqH0rFz5FvFQ1ZJ+2nzw9BX39bBIXp4u8eMDN1DE21vR1aprzeok21heXp7WrElSrdp3OrEy4PJSj51RTm6eakUE2MYigqwqEWDV9sMZTqwMyD+XWBjRuHFjxcfHq1GjRvrvf/+rzz//XJK0Y8cO07ewXMpqtZpuuO1ZxNthtd6Oqpbwk0XS4YxsFfcroo41SujI6Wyt3ntK3p4WtawSpi2HMnTq3Hn5e3uqScUQBfl4KfkKV/UBjvBoz94a8eLzql69hmrUrKVZM2fo7Nmz6vRgnLNLw23Ix8tDpf52B4cSAVZVCPXV6axcHcvMlr/VU8X9vBVa9MLvm4hgH0nSibM5Onn2vM7k5GrJjmPq3aCMTmfl6mx2rvrdW1Z/HM7gohUXdSsnfo7iEk3iO++8oyeffFJfffWV3n//fZUuXVqS9OOPP6p169ZOru725+vlofbViyvYx0uZOXn67cBpLfj9qPIMKc+QSgZYdXfZIPl7eyozO1d7T57Tmz/v1aHTrP3EzdO6TVudOH5c773zlo4dO6qoqtF674OPFcZ0MxygUnE/vfpAlO15n3vKSJKW7Timt1bu1t1lgzUopoJt+9D7Ltyube6GA5q74YAk6dPVf8loID3fPFJFPC1K3p+uD37hq2Zx67AYhmFce7dby6D5fzi7BMDk9XZVnV0CYKfr9HXOLgGwM79vfaedO6znvx127LQZ3Rx2bEdyiSRRknJzczV//nxt27ZNklS9enV16NBBnp5cQQsAAHCzuUSTmJKSorZt22r//v2KiroQ7yckJKhMmTL6/vvv+dYVAADgUKxJNHOJy1MHDRqkyMhI/fXXX9qwYYM2bNigvXv3qkKFCho0aJCzywMAAHA7LpEkrlixQqtXr1ZoaKhtLCwsTOPHj1ejRo2cWBkAAHAHJIlmLtEkWq1WnT5tvidfRkaGvL25nQ0AAHAsmkQzl5hubteunfr37681a9bIMAwZhqHVq1friSeeUIcOHZxdHgAAgNtxiSbxrbfeUmRkpBo2bCgfHx/5+Pjo3nvvVaVKlTRlyhRnlwcAAG53Fgc+blEu0SQGBwfr22+/1Y4dO/TVV1/pq6++0o4dOzRv3jwFBwc7uzwAAICbZuXKlWrfvr0iIiJksVg0f/58u+29evUyfT/0pV8+cvz4cT3yyCMKDAxUcHCw+vTpo4yMgn0lpNPWJMbHx191+/Lly21/njRpkqPLAQAAbsyV1iRmZmaqdu3aevzxxxUXd/mvHm3durWmTZtme37pVxQ/8sgjOnjwoH766Sfl5OSod+/e6t+/v+bMmZPvOpzWJCYnJ+drP1f6nwYAAOBobdq0UZs2ba66j9VqVXh4+GW3bdu2TQsXLtTatWtVv/6Fb7F5++231bZtW73xxhuKiIjIVx1OaxL/nhQCAAA4kyNDqaysLGVlZdmNWa1WU/pXEImJiSpRooRCQkJ033336dVXX1VYWJgkKSkpScHBwbYGUZJatGghDw8PrVmzRg8++GC+zuESaxIBAABuVwkJCQoKCrJ7JCQkXPfxWrdurc8++0xLly7Va6+9phUrVqhNmzbKzc2VJB06dEglSpSwe42Xl5dCQ0N16NChfJ/HJe6TCAAA4EyOTBKHDx9uuhbjRlLErl272v5cs2ZN1apVS5GRkUpMTFTz5s2v+7iXokkEAABuz5FN4o1OLV9LxYoVVaxYMaWkpKh58+YKDw/XkSNH7PY5f/68jh8/fsV1jJfDdDMAAMAtbN++fUpLS1OpUqUkSQ0bNtTJkye1fv162z7Lli1TXl6eGjRokO/jkiQCAAC40M1UMjIylJKSYnu+a9cubdy4UaGhoQoNDdXo0aPVuXNnhYeHKzU1VcOGDVOlSpXUqlUrSVJ0dLRat26tfv36aerUqcrJydFTTz2lrl275vvKZokkEQAAwKWsW7dOd955p+68805JF+4tfeedd+qVV16Rp6enNm3apA4dOqhKlSrq06eP6tWrp59//tluSnv27NmqWrWqmjdvrrZt26px48b68MMPC1QHSSIAAHB7rnRf5tjYWBmGccXtixYtuuYxQkNDC3Tj7MshSQQAAIAJSSIAAHB7rpQkugqSRAAAAJiQJAIAALdHkmhGkwgAAECPaMJ0MwAAAExIEgEAgNtjutmMJBEAAAAmJIkAAMDtkSSakSQCAADAhCQRAAC4PZJEM5JEAAAAmJAkAgAAt0eSaEaTCAAAQI9ownQzAAAATEgSAQCA22O62YwkEQAAACYkiQAAwO2RJJqRJAIAAMCEJBEAALg9gkQzkkQAAACYkCQCAAC3x5pEM5pEAADg9ugRzZhuBgAAgAlJIgAAcHtMN5uRJAIAAMCEJBEAALg9gkQzkkQAAACYkCQCAAC35+FBlHgpkkQAAACYkCQCAAC3x5pEM5pEAADg9rgFjhnTzQAAADAhSQQAAG6PINGMJBEAAAAmJIkAAMDtsSbRjCQRAAAAJiSJAADA7ZEkmpEkAgAAwIQkEQAAuD2CRDOaRAAA4PaYbjZjuhkAAAAmJIkAAMDtESSakSQCAADAhCQRAAC4PdYkmpEkAgAAwIQkEQAAuD2CRDOSRAAAAJiQJAIAALfHmkQzkkQAAACYkCQCAAC3R5BoRpIIAADcnsVicdijoFauXKn27dsrIiJCFotF8+fPt23LycnR888/r5o1a8rPz08RERF67LHHdODAAbtjlC9f3lTH+PHjC1QHTSIAAIALyczMVO3atfXuu++atp05c0YbNmzQiBEjtGHDBn3zzTfavn27OnToYNp3zJgxOnjwoO3x9NNPF6gOppsBAIDbc6Xp5jZt2qhNmzaX3RYUFKSffvrJbuydd97R3Xffrb1796ps2bK28YCAAIWHh193Hbdlk/hq6yrOLgEAXN5HXeo4uwTALWRlZSkrK8tuzGq1ymq1FsrxT506JYvFouDgYLvx8ePHa+zYsSpbtqy6d++uwYMHy8sr/60f080AAMDtOXJNYkJCgoKCguweCQkJhVL3uXPn9Pzzz6tbt24KDAy0jQ8aNEhz587V8uXLNWDAAI0bN07Dhg0r2GdiGIZRKFW6kPRzec4uATDx9uLfZHAtp8+ed3YJgJ3iAc6b4Gz42kqHHTvx2QbXnSRaLBbNmzdPnTp1Mm3LyclR586dtW/fPiUmJto1iZf69NNPNWDAAGVkZOQ7wbwtp5sBAAAKwpFrEgtzavminJwcPfzww9qzZ4+WLVt21QZRkho0aKDz589r9+7dioqKytc5aBIBAABuIRcbxJ07d2r58uUKCwu75ms2btwoDw8PlShRIt/noUkEAABuz5W+li8jI0MpKSm257t27dLGjRsVGhqqUqVK6aGHHtKGDRu0YMEC5ebm6tChQ5Kk0NBQeXt7KykpSWvWrFGzZs0UEBCgpKQkDR48WD169FBISEi+62BNInCTsCYRroY1iXA1zlyT2PiNnx127FVDmhRo/8TERDVr1sw03rNnT40aNUoVKlS47OuWL1+u2NhYbdiwQU8++aT++OMPZWVlqUKFCnr00UcVHx9foGlvkkQAAAAXEhsbq6tleNfK9+rWravVq1ffcB00iQAAwO250nSzq2D+CwAAACYkiQAAwO2RJJqRJAIAAMCEJBEAALg9gkQzkkQAAACYkCQCAAC3x5pEM5pEAADg9ugRzZhuBgAAgAlJIgAAcHtMN5uRJAIAAMCEJBEAALg9gkQzkkQAAACYkCQCAAC350GUaEKSCAAAABOSRAAA4PYIEs1oEgEAgNvjFjhmTDcDAADAhCQRAAC4PQ+CRBOSRAAAAJiQJAIAALfHmkQzkkQAAACYkCQCAAC3R5BoRpIIAAAAE5JEAADg9iwiSrwUTSIAAHB73ALHjOlmAAAAmJAkAgAAt8ctcMxIEgEAAGBCkggAANweQaIZSSIAAABMSBIBAIDb8yBKNCFJBAAAgAlJIgAAcHsEiWY0iQAAwO1xCxwzppsBAABgQpIIAADcHkGiGUkiAAAATEgSAQCA2+MWOGYkiQAAADAhSQQAAG6PHNGMJBEAAAAmJIkAAMDtcZ9EM5pEAADg9jzoEU2YbgYAAIAJSSIAAHB7TDebkSQCAADAhCQRAAC4PYJEM5JEAAAAmJAkAgAAt8eaRDOSRAAAABeycuVKtW/fXhEREbJYLJo/f77ddsMw9Morr6hUqVLy9fVVixYttHPnTrt9jh8/rkceeUSBgYEKDg5Wnz59lJGRUaA6aBIBAIDb87A47lFQmZmZql27tt59993Lbn/99df11ltvaerUqVqzZo38/PzUqlUrnTt3zrbPI488oq1bt+qnn37SggULtHLlSvXv379AdVgMwzAKXr5rSz+X5+wSABNvL/5NBtdy+ux5Z5cA2Cke4LxVcL3nbnbYsad1rXndr7VYLJo3b546deok6UKKGBERoeeee05DhgyRJJ06dUolS5bU9OnT1bVrV23btk3VqlXT2rVrVb9+fUnSwoUL1bZtW+3bt08RERH5Oje/tQAAABwoKytL6enpdo+srKzrOtauXbt06NAhtWjRwjYWFBSkBg0aKCkpSZKUlJSk4OBgW4MoSS1atJCHh4fWrFmT73PRJAIAALdnceAjISFBQUFBdo+EhITrqvPQoUOSpJIlS9qNlyxZ0rbt0KFDKlGihN12Ly8vhYaG2vbJD6df3Vy2bFnFxsYqJiZGsbGxioyMdHZJAAAAhWb48OGKj4+3G7NarU6qJv+uK0n8+eef1aNHDzVs2FD79++XJM2cOVOrVq0q8LHGjRsnHx8fvfbaa6pcubLKlCmjHj166KOPPjJdqQMAAOAIHhaLwx5Wq1WBgYF2j+ttEsPDwyVJhw8fths/fPiwbVt4eLiOHDlit/38+fM6fvy4bZ98fSYFLe7rr79Wq1at5Ovrq+TkZNuc+qlTpzRu3LiCHk49evTQhx9+qB07dmj//v2aMGGCJOnJJ59U1apVC3w8AACA21WFChUUHh6upUuX2sbS09O1Zs0aNWzYUJLUsGFDnTx5UuvXr7fts2zZMuXl5alBgwb5PleBp5tfffVVTZ06VY899pjmzp1rG2/UqJFeffXVgh5OknTmzBmtWrVKiYmJWr58uZKTk1WjRg3FxsZe1/EAAAAKwpXupZ2RkaGUlBTb8127dmnjxo0KDQ1V2bJl9eyzz+rVV19V5cqVVaFCBY0YMUIRERG2K6Cjo6PVunVr9evXT1OnTlVOTo6eeuopde3aNd9XNkvX0SRu375dTZs2NY0HBQXp5MmTBT2c7r33XiUnJys6OlqxsbF64YUX1LRpU4WEhBT4WAAAALe6devWqVmzZrbnF9cz9uzZU9OnT9ewYcOUmZmp/v376+TJk2rcuLEWLlwoHx8f22tmz56tp556Ss2bN5eHh4c6d+6st956q0B1FLhJDA8PV0pKisqXL283vmrVKlWsWLGgh9Mff/whPz8/Va1aVVWrVlV0dDQNIgAAuKlc6Wv5YmNjdbXbWFssFo0ZM0Zjxoy54j6hoaGaM2fODdVR4DWJ/fr10zPPPKM1a9bIYrHowIEDmj17toYMGaJ//vOfBS4gLS1Ny5Yt0z333KNFixapUaNGKl26tLp3766PPvqowMcDAADAjSvwN64YhqFx48YpISFBZ86ckXThMu4hQ4Zo7NixN1SMYRhav3693nnnHc2ePVt5eXnKzc0t8HH4xhW4Ir5xBa6Gb1yBq3HmN64M+Gqrw479wUPVHXZsR7rur+XLzs5WSkqKMjIyVK1aNfn7+19XARs2bFBiYqISExO1atUqnT59WjVr1rTdO7Fjx44FPiZN4o07cviw3p4yUUm/rNS5c+d0R5myemXMOFWrXsPZpd2yaBJv3Nw5szVj2ic6duyoqkRV1QsvjlDNWrWcXdYtiyYx/zZuWKc5Mz/V9m2/K+3YUY174y01jW1u2/7JB+9q6eIfdeTwIXkVKaKo6Grq/+Qzql6Dn8+CcGaT+M+vf3fYsd/vXM1hx3ak6/6/4e3trWrVbvxN33333brzzjsVExOjfv36qWnTpgoKCrrh4+L6paefUt9e3VWvfgO9+e6HCg4J1V979ygwMNDZpcGNLfzxB73xeoJeHjlaNWvW1uyZM/TPAX307YKFCgsLc3Z5uM2dPXtWlSpH6YEOcXpp6DOm7WXKldPgYS8povQdysrK0hdzPlP8wH6aO/9HhYSEOqFi4MYVuEls1qzZVRd3Llu2rEDHO378OM2Hi5nx6ccqWbKURo79//telr7jDidWBEgzZ0xT3EMPq9ODnSVJL48crZUrEzX/m6/Vp19/J1eH213DRk3UsFGTK25v2bqd3fOnBw/Tgm+/VurOHap/9z2OLg+FwIWuW3EZBW4S69SpY/c8JydHGzdu1JYtW9SzZ88CF0CD6Hp+XrFc99zbSC8MeVYb1q1V8RIl9VCXrnqw88POLg1uKic7W9t+36o+/QbYxjw8PHTPPfdq02/JTqwMMMvJyda3876Uv3+AKlWJcnY5wHUrcJM4efLky46PGjVKGRkZBS4gNzdXkydP1hdffKG9e/cqOzvbbvvx48cLfEzcmP37/tLXX8xV90d7qXef/tq6dYsmvjZORYp4q12HTs4uD27oxMkTys3NNU0rh4WFadeuP51UFWDvl58TNerFITp37pzCihXX5Hc/UnAwt3S7VbjSLXBcRaGtpO/Ro4c+/fTTAr9u9OjRmjRpkrp06aJTp04pPj5ecXFx8vDw0KhRo675+qysLKWnp9s9Ln5VIK5PXp6hqOhqGjhosKKiq12Y4ov7h775cu61XwwAbqpu/bs1bc7Xev/T2WrQsLFeGf6cThxPc3ZZwHUrtCYxKSnJ7k7f+TV79mx99NFHeu655+Tl5aVu3brp448/1iuvvKLVq1df8/UJCQkKCgqye0yaMP563gL+p1jxYqpYMdJurHzFijp08KCTKoK7CwkOkaenp9LS7H/hpqWlqVixYk6qCrDn61tUd5Qppxo1a2v4K2Pl6empBd9+4+yykE8eDnzcqgo83RwXF2f33DAMHTx4UOvWrdOIESMKXMChQ4dUs2ZNSZK/v79OnTolSWrXrl2+jjd8+HDb19VclGUUKXAd+H+169TVnt277cb27tmt8AJ83yNQmIp4eyu6WnWtWZ2k+5q3kCTl5eVpzZokde3Ww8nVAZeXl2eYllABt5ICN4mX3p7Gw8NDUVFRGjNmjFq2bFngAu644w4dPHhQZcuWVWRkpBYvXqy6detq7dq1slqt13y91Wo17cd9Em9Mtx491adnd037+AO1aNlaW7ds1ryvvtSLr4x2dmlwY4/27K0RLz6v6tVrqEbNWpo1c4bOnj2rTg/GXfvFwA06cyZT+//aa3t+cP8+7dy+TQFBQQoKCtZnn36oRk2bqVix4jp58oS++eLfOnb0sJq1aOXEqlEQrEk0K1CTmJubq969e6tmzZqF9v3KDz74oJYuXaoGDRro6aefVo8ePfTJJ59o7969Gjx4cKGcAwVTvUZNTZj0lt59a7I+/uA9RZS+Q/HDXlCbB9o7uzS4sdZt2urE8eN67523dOzYUUVVjdZ7H3ysMKabcRP88ftWDXqit+3525NflyS1addRQ4aP1J7du/Tjgm916uQJBQYFK7paDb370WeqGFnJWSWjgDzoEU0K/I0rPj4+2rZtmypUqOCQglavXq1ff/1VlStXVvv219eUkCTCFfGNK3A1fOMKXI0zv3Hl2W//cNixp3Ss6rBjO1KBf2vVqFFDf/5ZOLecyMnJ0eOPP65du3bZxu655x7Fx8dfd4MIAABQUB4Wxz1uVQVuEl999VUNGTJECxYs0MGDB023nymIIkWK6Ouvvy5oCQAAAHCwfDeJY8aMUWZmptq2bavffvtNHTp00B133KGQkBCFhIQoODj4utYpdurUSfPnzy/w6wAAAAqLxWJx2ONWle/J/9GjR+uJJ57Q8uXLC7WAypUra8yYMfrll19Ur149+fn52W0fNGhQoZ4PAAAA15bvC1c8PDx06NAhlShRolALuNoFMBaL5brWP3LhClwRF67A1XDhClyNMy9cGbpgu8OOPaHdrfkd3gX6v+GIyPTvF60AAADANRSoSaxSpco1G8Xjx49f8ziXfkPKlVgsFk2cODFf+wIAAFyvW3jpoMMUqEkcPXq06RtXrkdycrLd8w0bNuj8+fOKiroQx+7YsUOenp6qV6/eDZ8LAADgWjzoEk0K1CR27dq1UNYk/v3il0mTJikgIEAzZsywXR194sQJ9e7dW02aNLnhcwEAAKDg8n3hiqenpw4ePFjoF66ULl1aixcvVvXq1e3Gt2zZopYtW+rAgQMFPiYXrsAVceEKXA0XrsDVOPPClRd/2OGwY49rW8Vhx3akfP/WKuC39+Vbenq6jh49aho/evSoTp8+7ZBzAgAA4Ory3bLn5TkmnXvwwQfVu3dvTZw4UXfffbckac2aNRo6dKji4uIcck4AAIC/Y0mimfNy3f+ZOnWqhgwZou7duysnJ0eS5OXlpT59+mjChAlOrg4AAMA95XtNoqNlZmYqNTVVkhQZGWn65pWCYE0iXBFrEuFqWJMIV+PMNYkjFu502LHHtq7ssGM7ktOTxIv8/PxUq1YtZ5cBAAAAuVCTCAAA4CysSTSjSQQAAG7PgybRhEVSAAAAMCFJBAAAbo+v5TMjSQQAAIAJSSIAAHB7BIlmJIkAAAAwIUkEAABuj6ubzUgSAQAAYEKSCAAA3J5FRImXokkEAABuj+lmM6abAQAAYEKSCAAA3B5JohlJIgAAAExIEgEAgNuzcDdtE5JEAAAAmJAkAgAAt8eaRDOSRAAAAJiQJAIAALfHkkQzmkQAAOD2POgSTZhuBgAAgAlJIgAAcHtcuGJGkggAAAATmkQAAOD2LBbHPQqifPnyslgspsfAgQMlSbGxsaZtTzzxhAM+EaabAQAAXMbatWuVm5tre75lyxbdf//9+sc//mEb69evn8aMGWN7XrRoUYfUQpMIAADcnocctygxKytLWVlZdmNWq1VWq9W0b/Hixe2ejx8/XpGRkYqJibGNFS1aVOHh4Y4p9m+YbgYAAHCghIQEBQUF2T0SEhKu+brs7GzNmjVLjz/+uN13S8+ePVvFihVTjRo1NHz4cJ05c8YhdZMkAgAAt+fI2yQOHz5c8fHxdmOXSxEvNX/+fJ08eVK9evWyjXXv3l3lypVTRESENm3apOeff17bt2/XN998U9hly2IYhlHoR3Wy9HN5zi4BMPH2IriHazl99ryzSwDsFA9wXnY1NWm3w479RMPy1/W6Vq1aydvbW999990V91m2bJmaN2+ulJQURUZGXmeFl8dvLQAAABezZ88eLVmyRH379r3qfg0aNJAkpaSkFHoNTDcDAAC352pfyzdt2jSVKFFCDzzwwFX327hxoySpVKlShV4DTSIAAIALycvL07Rp09SzZ095ef1/q5aamqo5c+aobdu2CgsL06ZNmzR48GA1bdpUtWrVKvQ6aBIBAIDbc6UgccmSJdq7d68ef/xxu3Fvb28tWbJEU6ZMUWZmpsqUKaPOnTvr5ZdfdkgdXLgC3CRcuAJXw4UrcDXOvHDlozV7HHbsfg3KOezYjkSSCAAA3J6rrUl0BUQbAAAAMCFJBAAAbo8g0YwmEQAAuD2mVs34TAAAAGBCkggAANyehflmE5JEAAAAmJAkAgAAt0eOaEaSCAAAABOSRAAA4Pa4mbYZSSIAAABMSBIBAIDbI0c0o0kEAABuj9lmM6abAQAAYEKSCAAA3B430zYjSQQAAIAJSSIAAHB7pGZmfCYAAAAwIUkEAABujzWJZiSJAAAAMCFJBAAAbo8c0YwkEQAAACYkiQAAwO2xJtHstmwSP/7vbmeXAJg8eW9FZ5cA2Cnb9FlnlwDYOZv8jtPOzdSqGZ8JAAAATG7LJBEAAKAgmG42I0kEAACACUkiAABwe+SIZiSJAAAAMCFJBAAAbo8liWYkiQAAADAhSQQAAG7Pg1WJJjSJAADA7THdbMZ0MwAAAExIEgEAgNuzMN1sQpIIAAAAE5JEAADg9liTaEaSCAAAABOSRAAA4Pa4BY4ZSSIAAABMSBIBAIDbY02iGU0iAABwezSJZkw3AwAAwIQkEQAAuD1upm1GkggAAAATkkQAAOD2PAgSTUgSAQAAYEKSCAAA3B5rEs1IEgEAAGBCkggAANwe90k0I0kEAABuz+LA/wpi1KhRslgsdo+qVavatp87d04DBw5UWFiY/P391blzZx0+fLiwPw5JNIkAAAAupXr16jp48KDtsWrVKtu2wYMH67vvvtOXX36pFStW6MCBA4qLi3NIHUw3AwAAt+dKt8Dx8vJSeHi4afzUqVP65JNPNGfOHN13332SpGnTpik6OlqrV6/WPffcU6h1kCQCAAA4UFZWltLT0+0eWVlZV9x/586dioiIUMWKFfXII49o7969kqT169crJydHLVq0sO1btWpVlS1bVklJSYVeN00iAABwe45ck5iQkKCgoCC7R0JCwmXraNCggaZPn66FCxfq/fff165du9SkSROdPn1ahw4dkre3t4KDg+1eU7JkSR06dKjQPxOmmwEAABxo+PDhio+PtxuzWq2X3bdNmza2P9eqVUsNGjRQuXLl9MUXX8jX19ehdV6KJhEAALg9R94Cx2q1XrEpvJbg4GBVqVJFKSkpuv/++5Wdna2TJ0/apYmHDx++7BrGG8V0MwAAgIvKyMhQamqqSpUqpXr16qlIkSJaunSpbfv27du1d+9eNWzYsNDPTZIIAADcnqtc3DxkyBC1b99e5cqV04EDBzRy5Eh5enqqW7duCgoKUp8+fRQfH6/Q0FAFBgbq6aefVsOGDQv9ymaJJhEAAEAeLvKVK/v27VO3bt2Ulpam4sWLq3Hjxlq9erWKFy8uSZo8ebI8PDzUuXNnZWVlqVWrVnrvvfccUgtNIgAAgIuYO3fuVbf7+Pjo3Xff1bvvvuvwWmgSAQCA23ONHNG1cOEKAAAATEgSAQAAiBJNSBIBAABgQpIIAADcnoUo0YQkEQAAACYkiQAAwO25yG0SXQpNIgAAcHv0iGZMNwMAAMCEJBEAAIAo0YQkEQAAACYkiQAAwO1xCxwzkkQAAACYkCQCAAC3xy1wzEgSAQAAYEKSCAAA3B5BohlNIgAAAF2iCdPNAAAAMCFJBAAAbo9b4JiRJAIAAMCEJBEAALg9boFjRpIIAAAAE5JEAADg9ggSzUgSAQAAYEKSCAAAQJRoQpMIAADcHrfAMWO6GQAAACYkiQAAwO1xCxwzkkQAAACYkCQCAAC3R5Bo5vQmMTMzU+PHj9fSpUt15MgR5eXl2W3/888/nVQZAACA+3J6k9i3b1+tWLFCjz76qEqVKiULiwIAAMDNRvth4vQm8ccff9T333+vRo0aObsUAAAA/I/Tm8SQkBCFhoY6uwy3NfuFnspIO2IarxbbTk0eGagzp45r9VefaN/vyco5d0bB4XfozrZdVbFeYydUC3c3d85szZj2iY4dO6oqUVX1wosjVLNWLWeXhdtQo7qRGvxYC9WtVlaligfp4cEf6rvETbbtfr7eenVQR7VvVkuhQX7afSBN7/17hT7+apVtn5JhARr37IO6756qCvCzasfuI3r9k0Wav3SjE94RroX7JJo5vUkcO3asXnnlFc2YMUNFixZ1djluJ+6lN2X8bR3o8f179P3kFxVZv4kkafmnbyjrTKZaPzVSPv6BSlmTqCUfJCju5TdVrGwlZ5UNN7Twxx/0xusJennkaNWsWVuzZ87QPwf00bcLFiosLMzZ5eE24+dr1eYd+/XZt0n6fFJ/0/bXnuus2LuqqPdLn2nPgTS1aBitN4c/rINHT+n7FZslSR+PfUzBAb76x7Mf6NjJDHVpU1+zXntcjR55Xb9t33ez3xJQYE6/Bc7EiRO1aNEilSxZUjVr1lTdunXtHnAs34BgFQ0KtT32bFqjwOKlVKpKTUnSodRtqnFfB5WoEKXA4qVUt103eRf109E9KU6uHO5m5oxpinvoYXV6sLMiK1XSyyNHy8fHR/O/+drZpeE2tPiX3zX6vQX6z/JNl91+T+0KmrVgjX5ev1N7Dx7Xp9/8ok079qt+9XJ/26ei3pu7Quu27tHu/Wl67eNFOnn6rO6sVuZmvQ0UgMXiuMetyulJYqdOnZxdAv4n93yOUtYsV80WD9ouIAqPjFbq2pUqW+tuWX39lLpupXJzshURxRQfbp6c7Gxt+32r+vQbYBvz8PDQPffcq02/JTuxMrir1b/tUruYmvpsfpIOHD2lpvUrq3K5Eho28eu/7fOnHmpZTwt/3qqTp8/qoZZ15WP10sp1O51YOa7kFu7lHMbpTeLIkSOdXQL+Z3dykrLOZCiq0f22sRYDXtSSDxI049mH5eHpKS9vq1o+OUJBJSKcWCnczYmTJ5Sbm2uaVg4LC9OuXdwmCzdf/Gtf6t0R3ZS6+F/KyclVnpGnJ8f+W79sSLXt02PYp5r52uM6sOJ15eTk6sy5bHWJ/0h//nXMiZUD+ef0JvFGZWVlKSsry27sfHaWvLytTqro1vXHqkUqU6O+/IL//xfx2vmfKftsph6IHydf/yDtSk7Skg8S1GHYBIXdUcGJ1QKA8zzZNUZ31yyvzs9M1d6Dx9W4biVNeeHCmsTla7ZLkkYObKfgAF+1GfCW0k5mqn1sLc16/XG1eHyKtqYccPI7gAlRoolT1iSGhobq2LEL/5K6eHXzlR7XkpCQoKCgILvH0tlTHf0Wbjun0w5r/7aNim7S2jZ26sgBbV3+nWJ6DtYd0XcqrExF1e/wiIqXr6ytyxc4sVq4m5DgEHl6eiotLc1uPC0tTcWKFXNSVXBXPtYiGv10ez0/8Rv9sHKLtuw8oKmfr9RXizfo2UebS5Iq3FFM/+waowGjZinxvzu0ecd+jfvwR234fa8GdGnq5HcA5I9TksTJkycrICBAkjRlypQbOtbw4cMVHx9vNzb1v/tv6JjuaPsvP8k3MEhla95tGzuffSGhtXjY//PKYvGQYdh/Mw7gSEW8vRVdrbrWrE7Sfc1bSJLy8vK0Zk2Sunbr4eTq4G6KeHnKu4iX8gzDbjw3N08e//v7sqiPtyRdZh9DHrfylQy3MW6BY+aUJrFnz562Py9dulSxsbGKiYlRZGRkgY9ltVpltdpPLXt5s96jIIy8PG3/5SdVadhCHp6etvHg8DIKLBGhlTPfVsN/9JXVL0C7NyZp37ZktXl6lPMKhlt6tGdvjXjxeVWvXkM1atbSrJkzdPbsWXV6MM7ZpeE25OfrrcgyxW3Py5cOU60qpXUi/Yz+OnRCK9ft1LhnO+nsuRztPXhcTepV0iPt7tbzk76RJG3ffUgpe4/onZe7afikeUo7lakOzWqp+T1RinuG2S7cGiyGcck/c26yfv36acWKFUpNTVVERIRiYmJsTWPlypWv65iTVrKQvSD+2rpeP0x5WV3GfqTg8Dvstp06vF9rvpmmQzu3KifrrAJLRKh2y86q0rC5k6q9dT15b0Vnl3DL+/fsWbabaUdVjdbzL76sWrVqO7usW1bIXU85uwSX1aReZS3++BnT+Mz/rFb/kbNUMixAY57uqBYNqyoksOj/boPzq96atcy2b2TZ4np1UEc1rFNR/kWtSv3rqKZ8tlT//n7tzXwrt5Szye847dzbD51x2LGjwm/N+0A7vUm8aP/+/Vq5cqVWrFihFStWaMeOHSpVqpT27Sv4DUdpEuGKaBLhamgS4WpoEl2Ly1zdHBISorCwMIWEhCg4OFheXl4qXrz4tV8IAABwg1iRaOb0b1x58cUXde+99yosLEwvvPCCzp07pxdeeEGHDh1ScjI3yQUAADeBxYGPW5TTk8Tx48erePHiGjlypOLi4lSlShVnlwQAAOD2nN4kJicna8WKFUpMTNTEiRPl7e1tu3glNjaWphEAADgct8Axc3qTWLt2bdWuXVuDBg2SJP3222+aPHmyBg4cqLy8POXm5jq5QgAAAPfj9CbRMAwlJycrMTFRiYmJWrVqldLT01WrVi3FxMQ4uzwAAOAGuMe5mdMvXAkNDVWDBg00Z84cVa5cWTNmzNCxY8e0YcMGTZ482dnlAQAA3DQJCQm66667FBAQoBIlSqhTp07avn273T6xsbGyWCx2jyeeeKLQa3F6kjhr1iw1adJEgYGBzi4FAAC4KVcJElesWKGBAwfqrrvu0vnz5/Xiiy+qZcuW+v333+Xn52fbr1+/fhozZoztedGihX8vRqc3iQ888ICzSwAAAHAJCxcutHs+ffp0lShRQuvXr1fTpk1t40WLFlV4eLhDa3H6dDMAAIDTOfA+iVlZWUpPT7d7ZGVl5ausU6dOSbqwPO/vZs+erWLFiqlGjRoaPny4zpwp/G+MoUkEAABuz+LA/xISEhQUFGT3SEhIuGZNeXl5evbZZ9WoUSPVqFHDNt69e3fNmjVLy5cv1/DhwzVz5kz16NGj0D8Tp083AwAA3M6GDx+u+Ph4uzGr1XrN1w0cOFBbtmzRqlWr7Mb79+9v+3PNmjVVqlQpNW/eXKmpqYqMjCycokWTCAAA4NBb4Fit1nw1hX/31FNPacGCBVq5cqXuuOOOq+7boEEDSVJKSgpNIgAAwO3IMAw9/fTTmjdvnhITE1WhQoVrvmbjxo2SpFKlShVqLTSJAADA7bnKLXAGDhyoOXPm6Ntvv1VAQIAOHTokSQoKCpKvr69SU1M1Z84ctW3bVmFhYdq0aZMGDx6spk2bqlatWoVaC00iAACAi3j//fclXbhh9t9NmzZNvXr1kre3t5YsWaIpU6YoMzNTZcqUUefOnfXyyy8Xei00iQAAAC4SJRqGcdXtZcqU0YoVK25KLdwCBwAAACYkiQAAwO1ZXCVKdCE0iQAAwO058hY4tyqmmwEAAGBCkggAANweQaIZSSIAAABMSBIBAIDbY02iGUkiAAAATEgSAQAAWJVoQpIIAAAAE5JEAADg9liTaEaTCAAA3B49ohnTzQAAADAhSQQAAG6P6WYzkkQAAACYkCQCAAC3Z2FVoglJIgAAAExIEgEAAAgSTUgSAQAAYEKSCAAA3B5BohlNIgAAcHvcAseM6WYAAACYkCQCAAC3xy1wzEgSAQAAYEKSCAAAQJBoQpIIAAAAE5JEAADg9ggSzUgSAQAAYEKSCAAA3B73STSjSQQAAG6PW+CYMd0MAAAAE5JEAADg9phuNiNJBAAAgAlNIgAAAExoEgEAAGDCmkQAAOD2WJNoRpIIAAAAE5JEAADg9rhPohlNIgAAcHtMN5sx3QwAAAATkkQAAOD2CBLNSBIBAABgQpIIAABAlGhCkggAAAATkkQAAOD2uAWOGUkiAAAATEgSAQCA2+M+iWYkiQAAADAhSQQAAG6PINGMJhEAAIAu0YTpZgAAAJjQJAIAALdnceB/1+Pdd99V+fLl5ePjowYNGui///1vIb/ja6NJBAAAcCGff/654uPjNXLkSG3YsEG1a9dWq1atdOTIkZtaB00iAABwexaL4x4FNWnSJPXr10+9e/dWtWrVNHXqVBUtWlSffvpp4b/xq6BJBAAAcKCsrCylp6fbPbKysi67b3Z2ttavX68WLVrYxjw8PNSiRQslJSXdrJIl3aZXN8c3rejsEm4LWVlZSkhI0PDhw2W1Wp1dDsDPZCE7m/yOs0u4LfBzeXvwcWBHNOrVBI0ePdpubOTIkRo1apRp32PHjik3N1clS5a0Gy9ZsqT++OMPxxV5GRbDMIybekbcMtLT0xUUFKRTp04pMDDQ2eUA/EzCJfFziWvJysoyJYdWq/Wy/6g4cOCASpcurV9//VUNGza0jQ8bNkwrVqzQmjVrHF7vRbdlkggAAOAqrtQQXk6xYsXk6empw4cP240fPnxY4eHhjijviliTCAAA4CK8vb1Vr149LV261DaWl5enpUuX2iWLNwNJIgAAgAuJj49Xz549Vb9+fd19992aMmWKMjMz1bt375taB00irshqtWrkyJEsxIbL4GcSroifSxS2Ll266OjRo3rllVd06NAh1alTRwsXLjRdzOJoXLgCAAAAE9YkAgAAwIQmEQAAACY0iQAAADChSXQjsbGxevbZZ51dBnBZ/HziVjV9+nQFBwc7uwyg0NEkAgBwA7p06aIdO3Y4uwyg0HELHAAuLzs7W97e3s4uA7gsX19f+fr6OrsMoNCRJLqpEydO6LHHHlNISIiKFi2qNm3aaOfOnbbte/bsUfv27RUSEiI/Pz9Vr15dP/zwg237li1b1KZNG/n7+6tkyZJ69NFHdezYMWe8FdyCMjMz9dhjj8nf31+lSpXSxIkT7baXL19eY8eO1WOPPabAwED1799fkvT888+rSpUqKlq0qCpWrKgRI0YoJydHknTq1Cl5enpq3bp1ki58Q0FoaKjuuece23FnzZqlMmXK3KR3iVvZggULFBwcrNzcXEnSxo0bZbFY9MILL9j26du3r3r06GGabh41apTq1KmjmTNnqnz58goKClLXrl11+vTpm/02gBtCk+imevXqpXXr1uk///mPkpKSZBiG2rZta/uFO3DgQGVlZWnlypXavHmzXnvtNfn7+0uSTp48qfvuu0933nmn1q1bp4ULF+rw4cN6+OGHnfmWcAsZOnSoVqxYoW+//VaLFy9WYmKiNmzYYLfPG2+8odq1ays5OVkjRoyQJAUEBGj69On6/fff9eabb+qjjz7S5MmTJUlBQUGqU6eOEhMTJUmbN2+WxWJRcnKyMjIyJEkrVqxQTEzMzXujuGU1adJEp0+fVnJysqQLPzvFihWz/XxdHIuNjb3s61NTUzV//nwtWLBACxYs0IoVKzR+/PibUDlQiAy4jZiYGOOZZ54xduzYYUgyfvnlF9u2Y8eOGb6+vsYXX3xhGIZh1KxZ0xg1atRljzN27FijZcuWdmN//fWXIcnYvn27494AbgunT582vL29bT9rhmEYaWlphq+vr/HMM88YhmEY5cqVMzp16nTNY02YMMGoV6+e7Xl8fLzxwAMPGIZhGFOmTDG6dOli1K5d2/jxxx8NwzCMSpUqGR9++GEhvhvczurWrWtMmDDBMAzD6NSpk/Gvf/3L8Pb2Nk6fPm3s27fPkGTs2LHDmDZtmhEUFGR73ciRI42iRYsa6enptrGhQ4caDRo0uNlvAbghJIluaNu2bfLy8lKDBg1sY2FhYYqKitK2bdskSYMGDdKrr76qRo0aaeTIkdq0aZNt399++03Lly+Xv7+/7VG1alVJF/71DFxNamqqsrOz7X7+QkNDFRUVZbdf/fr1Ta/9/PPP1ahRI4WHh8vf318vv/yy9u7da9seExOjVatWKTc315byxMbGKjExUQcOHFBKSsoVkx/gUjExMUpMTJRhGPr5558VFxen6OhorVq1SitWrFBERIQqV6582deWL19eAQEBtuelSpXSkSNHblbpQKGgScRl9e3bV3/++aceffRRbd68WfXr19fbb78tScrIyFD79u21ceNGu8fOnTvVtGlTJ1eO24Wfn5/d86SkJD3yyCNq27atFixYoOTkZL300kvKzs627dO0aVOdPn1aGzZs0MqVK+2axGv9UgcuFRsbq1WrVum3335TkSJFVLVqVbufp6stXShSpIjdc4vFory8PEeXDBQqmkQ3FB0drfPnz2vNmjW2sbS0NG3fvl3VqlWzjZUpU0ZPPPGEvvnmGz333HP66KOPJEl169bV1q1bVb58eVWqVMnucekvduBSkZGRKlKkiN3P34kTJ655C5Fff/1V5cqV00svvaT69eurcuXK2rNnj90+wcHBqlWrlt555x3bL/WmTZsqOTlZCxYsYD0iCuTiusTJkyfbfnYuNomJiYmk0rjt0SS6ocqVK6tjx47q16+f7V/JPXr0UOnSpdWxY0dJ0rPPPqtFixZp165d2rBhg5YvX67o6GhJFy5qOX78uLp166a1a9cqNTVVixYtUu/evW1XAgJX4u/vrz59+mjo0KFatmyZtmzZol69esnD4+p/HVWuXFl79+7V3LlzlZqaqrfeekvz5s0z7RcbG6vZs2fbfqmHhoYqOjpan3/+OU0iCiQkJES1atXS7NmzbQ1h06ZNtWHDBu3YsYOfJ9z2aBLd1LRp01SvXj21a9dODRs2lGEY+uGHH2xTJLm5uRo4cKCio6PVunVrValSRe+9954kKSIiQr/88otyc3PVsmVL1axZU88++6yCg4Ov+YsekKQJEyaoSZMmat++vVq0aKHGjRurXr16V31Nhw4dNHjwYD311FOqU6eOfv31V9tVz38XExOj3Nxcu5QnNjbWNAbkx6U/T6GhoapWrZrCw8NN62iB243FMAzD2UUAAADAtRD7AAAAwIQmEQAAACY0iQAAADChSQQAAIAJTSIAAABMaBIBAABgQpMIAAAAE5pEAAAAmNAkAnBZvXr1UqdOnWzPY2Nj9eyzz970OhITE2WxWHTy5Mmbfm4AcBaaRAAF1qtXL1ksFlksFnl7e6tSpUoaM2aMzp8/79DzfvPNNxo7dmy+9qWxA4Ab4+XsAgDcmlq3bq1p06YpKytLP/zwgwYOHKgiRYpo+PDhdvtlZ2fL29u7UM4ZGhpaKMcBAFwbSSKA62K1WhUeHq5y5crpn//8p1q0aKH//Oc/tinif/3rX4qIiFBUVJQk6a+//tLDDz+s4OBghYaGqmPHjtq9e7fteLm5uYqPj1dwcLDCwsI0bNgwXfrV8pdON2dlZen5559XmTJlZLVaValSJX3yySfavXu3mjVrJkkKCQmRxWJRr169JEl5eXlKSEhQhQoV5Ovrq9q1a+urr76yO88PP/ygKlWqyNfXV82aNbOrEwDcBU0igELh6+ur7OxsSdLSpUu1fft2/fTTT1qwYIFycnLUqlUrBQQE6Oeff9Yvv/wif39/tW7d2vaaiRMnavr06fr000+1atUqHT9+XPPmzbvqOR977DH9+9//1ltvvaVt27bpgw8+kL+/v8qUKaOvv/5akrR9+3YdPHhQb775piQpISFBn332maZOnaqtW7dq8ODB6tGjh1asWCHpQjMbFxen9u3ba+PGjerbt69eeOEFR31sAOCymG4GcEMMw9DSpUu1aNEiPf300zp69Kj8/Pz08ccf26aZZ82apby8PH388ceyWCySpGnTpik4OFiJiYlq2bKlpkyZouHDhysuLk6SNHXqVC1atOiK592xY4e++OIL/fTTT2rRooUkqWLFirbtF6emS5QooeDgYEkXksdx48ZpyZIlatiwoe01q1at0gcffKCYmBi9//77ioyM1MSJEyVJUVFR2rx5s1577bVC/NQAwPXRJAK4LgsWLJC/v79ycnKUl5en7t27a9SoURo4cKBq1qxptw7xt99+U0pKigICAuyOce7cOaWmpurUqVM6ePCgGjRoYNvm5eWl+vXrm6acL9q4caM8PT0VExOT75pTUlJ05swZ3X///Xbj2dnZuvPOOyVJ27Zts6tDkq2hBAB3QpMI4Lo0a9ZM77//vry9vRURESEvr///68TPz89u34yMDNWrV0+zZ882Had48eLXdX5fX98CvyYjI0OS9P3336t06dJ226xW63XVAQC3K5pEANfFz89PlSpVyte+devW1eeff64SJUooMDDwsvuUKlVKa9asUdOmTSVJ58+f1/r161W3bt3L7l+zZk3l5eVpxYoVtunmv7uYZObm5trGqlWrJqvVqr17914xgYyOjtZ//vMfu7HVq1df+00CwG2GC1cAONwjjzyiYsWKqWPHjvr555+1a9cuJSYmatCgQdq3b58k6ZlnntH48eM1f/58/fHHH3ryySeveo/D8uXLq2fPnnr88cc1f/582zG/+OILSVK5cuVksVi0YMECHT16VBkZGQoICNCQIUM0ePBgzZgxQ6mpqdqwYYPefvttzZgxQ5L0xBNPaOfOnRo6dKi2b9+uOXPmaPr06Y7+iADA5dAkAnC4okWLauXKlSpbtqzi4uIUHR2tPn366Ny5c7Zk8bnnntOjjz6qnj17qmHDhgoICNCDDz541eO+//77euihh/Tkk0+qatWq6tevnzIzMyVJpUuX1ujRo/XCCy+oZMmSeuqppyRJY8eO1YgRI5SQkKDo6Gi1bt1a33//vSpUqCBJKlu2rL7++mvNnz9ftWvX1tSpUzVu3DgHfjoA4JosxpVWhQMAAMBtkSQCAADAhCYRAAAAJjSJAAAAMKFJBAAAgAlNIgAAAExoEgEAAGBCkwgAAAATmkQAAACY0CQCAADAhCYRAAAAJjSJAAAAMPk/7mk9YJvnLy4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = RF.predict(X_F)\n",
    "plot_confusion_matrix(y_F, y_pred, [\"lose\",\"draw\",\"win\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b837339d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': 0.5828214462130082,\n",
       " 'Test': 0.5331472623686698,\n",
       " 'Test_Final': 0.5555675736578222}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test(RF, X, y, X_F, y_F, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5c704bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_F, y_pred, [\"lose\",\"draw\",\"win\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "# RidgeClassifier\n",
    "# RidgeClassifierCV\n",
    "# LinearDiscriminantAnalysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cba5955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 729 candidates, totalling 1458 fits\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.2, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.0, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.01, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.001, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=2, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=3, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.3; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.45; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.4, gamma=0.02, learning_rate=0.0005, max_depth=4, min_child_weight=6, n_estimators=100, subsample=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "972 fits failed out of a total of 1458.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "486 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "486 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"D:\\LichessData\\venv\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.4 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.50734756 0.5147991  0.50941128 0.50983307 0.51417349 0.50775581\n",
      " 0.51097409 0.51588478 0.50984745 0.49372857 0.49935222 0.49837943\n",
      " 0.49696069 0.49865404 0.4995618  0.5022517  0.503518   0.49853519\n",
      " 0.48140348 0.47659436 0.48682186 0.48572286 0.47928872 0.48329418\n",
      " 0.48956388 0.47908296 0.484625   0.52450628 0.5210369  0.53036028\n",
      " 0.52233853 0.52214223 0.52934921 0.52371153 0.52154454 0.52973665\n",
      " 0.52200959 0.51517778 0.52154129 0.52211414 0.51890971 0.5242492\n",
      " 0.52453046 0.52098525 0.52487559 0.50782618 0.50579472 0.5175861\n",
      " 0.51169705 0.5050293  0.51522885 0.51724681 0.5128804  0.51768879\n",
      " 0.52489574 0.52375865 0.53280294 0.52468848 0.52354062 0.53304638\n",
      " 0.52665322 0.52340003 0.53300529 0.52221416 0.51595894 0.52605898\n",
      " 0.52341794 0.51929256 0.52392645 0.52526076 0.52266342 0.52312095\n",
      " 0.50820409 0.50665896 0.51605041 0.51231367 0.51088859 0.51703739\n",
      " 0.51858839 0.51512911 0.51726765 0.50734756 0.5147991  0.50941128\n",
      " 0.50983307 0.51417349 0.50775581 0.51097409 0.51588478 0.50984745\n",
      " 0.49367255 0.49935222 0.49877185 0.49659558 0.49865404 0.4995618\n",
      " 0.5022517  0.50323977 0.49882456 0.48181353 0.47659436 0.48682186\n",
      " 0.48572286 0.47947239 0.48329418 0.48925971 0.47908296 0.48601133\n",
      " 0.52450628 0.5210369  0.53036028 0.52233853 0.52214223 0.52934921\n",
      " 0.52371153 0.52154454 0.52973665 0.52200959 0.51517778 0.52154129\n",
      " 0.52211414 0.51890971 0.5242492  0.52453046 0.52098525 0.52487559\n",
      " 0.50782618 0.50574789 0.5175861  0.51169705 0.5050293  0.51522885\n",
      " 0.51724681 0.51291915 0.51768879 0.52489574 0.52375865 0.53280294\n",
      " 0.52468848 0.52354062 0.53304638 0.52665322 0.52340003 0.53300529\n",
      " 0.52221416 0.51595894 0.52605898 0.52341794 0.51929256 0.52392645\n",
      " 0.52526076 0.52266342 0.52312095 0.50820409 0.50665896 0.51605041\n",
      " 0.51231367 0.51088859 0.51681234 0.51858839 0.51531235 0.5170434\n",
      " 0.50734756 0.5147991  0.50941128 0.50983307 0.51417349 0.50775581\n",
      " 0.51097409 0.51588478 0.50984745 0.49367255 0.49898199 0.49877185\n",
      " 0.49659558 0.49865404 0.4995618  0.5022517  0.50323977 0.49824556\n",
      " 0.4810213  0.47630879 0.48682186 0.48584747 0.48016806 0.48299669\n",
      " 0.48974607 0.47878526 0.48601133 0.52450628 0.5210369  0.53036028\n",
      " 0.52233853 0.52214223 0.52934921 0.52371153 0.52154454 0.52973665\n",
      " 0.52200959 0.51526425 0.52154129 0.52173815 0.51890971 0.5242492\n",
      " 0.52453046 0.52098525 0.52487559 0.50811931 0.50611569 0.5175861\n",
      " 0.51169705 0.5050293  0.51522885 0.51720488 0.51291915 0.51768879\n",
      " 0.52489574 0.52375865 0.53280294 0.52468848 0.52354062 0.53304638\n",
      " 0.52665322 0.52340003 0.53300529 0.52221416 0.51595894 0.52605898\n",
      " 0.52341794 0.51968583 0.52392645 0.52526076 0.52266342 0.52312095\n",
      " 0.50845556 0.50665896 0.51605041 0.51231367 0.51088859 0.51681234\n",
      " 0.51815365 0.51531235 0.5170434         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0, 1.2, 1.4],\n",
       "                         &#x27;gamma&#x27;: [0.0, 0.01, 0.02],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.001, 0.0005],\n",
       "                         &#x27;max_depth&#x27;: [2, 3, 4], &#x27;min_child_weight&#x27;: [4, 5, 6],\n",
       "                         &#x27;n_estimators&#x27;: [100], &#x27;subsample&#x27;: [0.3, 0.45, 0.6]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0, 1.2, 1.4],\n",
       "                         &#x27;gamma&#x27;: [0.0, 0.01, 0.02],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.001, 0.0005],\n",
       "                         &#x27;max_depth&#x27;: [2, 3, 4], &#x27;min_child_weight&#x27;: [4, 5, 6],\n",
       "                         &#x27;n_estimators&#x27;: [100], &#x27;subsample&#x27;: [0.3, 0.45, 0.6]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'colsample_bytree': [1.0, 1.2, 1.4],\n",
       "                         'gamma': [0.0, 0.01, 0.02],\n",
       "                         'learning_rate': [0.01, 0.001, 0.0005],\n",
       "                         'max_depth': [2, 3, 4], 'min_child_weight': [4, 5, 6],\n",
       "                         'n_estimators': [100], 'subsample': [0.3, 0.45, 0.6]},\n",
       "             scoring='f1_weighted', verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'learning_rate': [0.01, 0.001, 0.0005],\n",
    "    'min_child_weight': [4, 5, 6],\n",
    "    'gamma': [0.0, 0.01, 0.02],\n",
    "    'subsample': [0.3,0.45, 0.6],\n",
    "    'colsample_bytree': [1.0, 1.2, 1.4]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=2, verbose=2, scoring= 'f1_weighted')\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3b92b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'gamma': 0.0,\n",
       " 'learning_rate': 0.0005,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 5,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74603ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_params= {'colsample_bytree': 1.0,\n",
    " 'gamma': 0.0,\n",
    " 'learning_rate': 0.001,\n",
    " 'max_depth': 3,\n",
    " 'min_child_weight': 5,\n",
    " 'n_estimators': 1000,\n",
    " 'subsample': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb1879bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(**XGB_params)\n",
    "model_test(model_xgb, X, y, X_F, y_F, n=5)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "plot_confusion_matrix(y_test, y_pred, [\"lose\",\"draw\",\"win\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a99ecb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': 0.5625609298013052,\n",
       " 'Test': 0.5378882248525905,\n",
       " 'Test_Final': 0.5648734616681768}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test(model_xgb, X, y, X_F, y_F, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34152a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=   2.3s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=   2.4s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=   2.3s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=   6.8s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=   6.6s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=   6.4s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  27.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  27.2s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  18.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.001, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  20.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=   5.4s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=   5.7s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=   5.6s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.1s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  10.9s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  10.7s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  29.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  29.5s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  20.1s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  17.4s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  16.8s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  15.6s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.8s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.7s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  10.8s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   3.9s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  31.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  32.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  30.4s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  18.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  19.2s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  18.9s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  18.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.1s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  10.8s\n",
      "[CV] END C=1, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  33.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  32.1s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  33.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  18.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.7s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  20.8s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  21.1s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  19.4s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.9s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.7s\n",
      "[CV] END C=10, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.5s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  35.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  33.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  34.2s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  18.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.7s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  20.7s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  21.2s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l1, solver=saga; total time=  21.2s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  11.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  10.9s\n",
      "[CV] END C=100, class_weight=None, max_iter=10000, penalty=l2, solver=saga; total time=  10.8s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l1, solver=liblinear; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  35.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  34.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l1, solver=saga; total time=  36.0s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  18.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.7s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=10000, penalty=l2, solver=saga; total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LichessData\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [10000], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [10000], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'class_weight': [None, 'balanced'],\n",
       "                         'max_iter': [10000], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'saga']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = linear_model.LogisticRegression()\n",
    "param_grid = {\n",
    "    'max_iter': [10000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=3, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6db727d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': 0.5518151019439916,\n",
       " 'Test': 0.5369235615031387,\n",
       " 'Test_Final': 0.5455092354071877}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression_params = {'C': 0.01,\n",
    " 'class_weight': None,\n",
    " 'max_iter': 10000,\n",
    " 'penalty': 'l2',\n",
    " 'solver': 'liblinear'}\n",
    "LR = linear_model.LogisticRegression(**LogisticRegression_params)\n",
    "model_test(LR, X, y, X_F, y_F, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e79ee545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=1, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=10, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=None, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=True, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=auto; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=svd; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=cholesky; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=lsqr; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n",
      "[CV] END alpha=100, class_weight=balanced, fit_intercept=False, max_iter=2000, solver=sparse_cg; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RidgeClassifier(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False], &#x27;max_iter&#x27;: [2000],\n",
       "                         &#x27;solver&#x27;: [&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;, &#x27;lsqr&#x27;,\n",
       "                                    &#x27;sparse_cg&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RidgeClassifier(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False], &#x27;max_iter&#x27;: [2000],\n",
       "                         &#x27;solver&#x27;: [&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;, &#x27;lsqr&#x27;,\n",
       "                                    &#x27;sparse_cg&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RidgeClassifier(),\n",
       "             param_grid={'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'class_weight': [None, 'balanced'],\n",
       "                         'fit_intercept': [True, False], 'max_iter': [2000],\n",
       "                         'solver': ['auto', 'svd', 'cholesky', 'lsqr',\n",
       "                                    'sparse_cg']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = linear_model.RidgeClassifier()\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg'],\n",
    "    'fit_intercept': [True, False],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    \"max_iter\": [2000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=3, verbose=2)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98503a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': 0.5360922329722925,\n",
       " 'Test': 0.5302618437500146,\n",
       " 'Test_Final': 0.5515621535526278}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC = linear_model.RidgeClassifier(**grid_search.best_params_)\n",
    "model_test(RC, X, y, X_F, y_F, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a69e6b",
   "metadata": {},
   "source": [
    "# Some basic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edc39eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "87b08681",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([blitz, bullet])\n",
    "Test = pd.concat([rapid, classical])\n",
    "\n",
    "X = Train.drop(\"i_won\", axis=1)\n",
    "y = Train[\"i_won\"]\n",
    "\n",
    "X_F = Test.drop([\"i_won\"], axis=1)\n",
    "y_F = Test[\"i_won\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 8)\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')\n",
    "\n",
    "X_F = np.asarray(X_F).astype('float32')\n",
    "y_F = np.asarray(y_F).astype('float32')\n",
    "\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "53fd67cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "52/52 [==============================] - 1s 5ms/step - loss: 18.1360 - accuracy: 0.4688 - val_loss: 4.7869 - val_accuracy: 0.5077\n",
      "Epoch 2/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 3.6211 - accuracy: 0.4877 - val_loss: 6.3486 - val_accuracy: 0.4594\n",
      "Epoch 3/110\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 3.3096 - accuracy: 0.4913 - val_loss: 1.0663 - val_accuracy: 0.5406\n",
      "Epoch 4/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.5304 - accuracy: 0.5002 - val_loss: 2.0260 - val_accuracy: 0.4622\n",
      "Epoch 5/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.6300 - accuracy: 0.4868 - val_loss: 1.3919 - val_accuracy: 0.4968\n",
      "Epoch 6/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0777 - accuracy: 0.5062 - val_loss: 0.9646 - val_accuracy: 0.5068\n",
      "Epoch 7/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0472 - accuracy: 0.5166 - val_loss: 1.0843 - val_accuracy: 0.4977\n",
      "Epoch 8/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9197 - accuracy: 0.4886 - val_loss: 1.0209 - val_accuracy: 0.5023\n",
      "Epoch 9/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8754 - accuracy: 0.5141 - val_loss: 0.8322 - val_accuracy: 0.5552\n",
      "Epoch 10/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9712 - accuracy: 0.5102 - val_loss: 1.0310 - val_accuracy: 0.4850\n",
      "Epoch 11/110\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.9922 - accuracy: 0.4892 - val_loss: 0.8798 - val_accuracy: 0.5141\n",
      "Epoch 12/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8886 - accuracy: 0.5078 - val_loss: 1.1469 - val_accuracy: 0.4649\n",
      "Epoch 13/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9550 - accuracy: 0.4962 - val_loss: 0.9460 - val_accuracy: 0.4941\n",
      "Epoch 14/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8751 - accuracy: 0.5245 - val_loss: 0.8411 - val_accuracy: 0.5542\n",
      "Epoch 15/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8718 - accuracy: 0.5202 - val_loss: 0.8614 - val_accuracy: 0.4932\n",
      "Epoch 16/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8884 - accuracy: 0.5187 - val_loss: 0.8255 - val_accuracy: 0.5442\n",
      "Epoch 17/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8509 - accuracy: 0.5144 - val_loss: 0.8406 - val_accuracy: 0.5524\n",
      "Epoch 18/110\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.8798 - accuracy: 0.5242 - val_loss: 0.9925 - val_accuracy: 0.4959\n",
      "Epoch 19/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8353 - accuracy: 0.5211 - val_loss: 0.8657 - val_accuracy: 0.5169\n",
      "Epoch 20/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8460 - accuracy: 0.5135 - val_loss: 1.0801 - val_accuracy: 0.4686\n",
      "Epoch 21/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8624 - accuracy: 0.5017 - val_loss: 0.8837 - val_accuracy: 0.4977\n",
      "Epoch 22/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8519 - accuracy: 0.5196 - val_loss: 0.8200 - val_accuracy: 0.5552\n",
      "Epoch 23/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8312 - accuracy: 0.5284 - val_loss: 0.8540 - val_accuracy: 0.5469\n",
      "Epoch 24/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8153 - accuracy: 0.5193 - val_loss: 0.8419 - val_accuracy: 0.5360\n",
      "Epoch 25/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8100 - accuracy: 0.5211 - val_loss: 0.8331 - val_accuracy: 0.5068\n",
      "Epoch 26/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8320 - accuracy: 0.5169 - val_loss: 0.8362 - val_accuracy: 0.5369\n",
      "Epoch 27/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8292 - accuracy: 0.5202 - val_loss: 0.8373 - val_accuracy: 0.5223\n",
      "Epoch 28/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8409 - accuracy: 0.5217 - val_loss: 0.9789 - val_accuracy: 0.5032\n",
      "Epoch 29/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8438 - accuracy: 0.5144 - val_loss: 0.8482 - val_accuracy: 0.5087\n",
      "Epoch 30/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8556 - accuracy: 0.5087 - val_loss: 0.8520 - val_accuracy: 0.5169\n",
      "Epoch 31/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8277 - accuracy: 0.5196 - val_loss: 0.8036 - val_accuracy: 0.5433\n",
      "Epoch 32/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8097 - accuracy: 0.5439 - val_loss: 0.8194 - val_accuracy: 0.5579\n",
      "Epoch 33/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8253 - accuracy: 0.5315 - val_loss: 0.8336 - val_accuracy: 0.5260\n",
      "Epoch 34/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8303 - accuracy: 0.5193 - val_loss: 0.8221 - val_accuracy: 0.5706\n",
      "Epoch 35/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8096 - accuracy: 0.5266 - val_loss: 0.8235 - val_accuracy: 0.5488\n",
      "Epoch 36/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8098 - accuracy: 0.5452 - val_loss: 0.8463 - val_accuracy: 0.5515\n",
      "Epoch 37/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8608 - accuracy: 0.5154 - val_loss: 0.8171 - val_accuracy: 0.5606\n",
      "Epoch 38/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8356 - accuracy: 0.5160 - val_loss: 0.8305 - val_accuracy: 0.5433\n",
      "Epoch 39/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8163 - accuracy: 0.5260 - val_loss: 0.8382 - val_accuracy: 0.5360\n",
      "Epoch 40/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8087 - accuracy: 0.5327 - val_loss: 0.8339 - val_accuracy: 0.4932\n",
      "Epoch 41/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8117 - accuracy: 0.5126 - val_loss: 0.8140 - val_accuracy: 0.5552\n",
      "Epoch 42/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8096 - accuracy: 0.5406 - val_loss: 0.8115 - val_accuracy: 0.5387\n",
      "Epoch 43/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7954 - accuracy: 0.5409 - val_loss: 0.8151 - val_accuracy: 0.5433\n",
      "Epoch 44/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8059 - accuracy: 0.5385 - val_loss: 0.8061 - val_accuracy: 0.5652\n",
      "Epoch 45/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8110 - accuracy: 0.5330 - val_loss: 0.8258 - val_accuracy: 0.5524\n",
      "Epoch 46/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8026 - accuracy: 0.5415 - val_loss: 0.8137 - val_accuracy: 0.5533\n",
      "Epoch 47/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8031 - accuracy: 0.5445 - val_loss: 0.8322 - val_accuracy: 0.5542\n",
      "Epoch 48/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8028 - accuracy: 0.5458 - val_loss: 0.8430 - val_accuracy: 0.5378\n",
      "Epoch 49/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8133 - accuracy: 0.5306 - val_loss: 0.8516 - val_accuracy: 0.5342\n",
      "Epoch 50/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8118 - accuracy: 0.5461 - val_loss: 0.8075 - val_accuracy: 0.5552\n",
      "Epoch 51/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8114 - accuracy: 0.5299 - val_loss: 0.8104 - val_accuracy: 0.5561\n",
      "Epoch 52/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8053 - accuracy: 0.5269 - val_loss: 0.8137 - val_accuracy: 0.5552\n",
      "Epoch 53/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7977 - accuracy: 0.5448 - val_loss: 0.8114 - val_accuracy: 0.5579\n",
      "Epoch 54/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8004 - accuracy: 0.5412 - val_loss: 0.8184 - val_accuracy: 0.5634\n",
      "Epoch 55/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7995 - accuracy: 0.5537 - val_loss: 0.8479 - val_accuracy: 0.4968\n",
      "Epoch 56/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8028 - accuracy: 0.5403 - val_loss: 0.8094 - val_accuracy: 0.5552\n",
      "Epoch 57/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7942 - accuracy: 0.5421 - val_loss: 0.8355 - val_accuracy: 0.4959\n",
      "Epoch 58/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7977 - accuracy: 0.5287 - val_loss: 0.8082 - val_accuracy: 0.5725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7968 - accuracy: 0.5458 - val_loss: 0.8309 - val_accuracy: 0.5232\n",
      "Epoch 60/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7947 - accuracy: 0.5403 - val_loss: 0.8075 - val_accuracy: 0.5624\n",
      "Epoch 61/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7941 - accuracy: 0.5491 - val_loss: 0.8155 - val_accuracy: 0.5479\n",
      "Epoch 62/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7951 - accuracy: 0.5540 - val_loss: 0.8140 - val_accuracy: 0.5643\n",
      "Epoch 63/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7986 - accuracy: 0.5339 - val_loss: 0.8659 - val_accuracy: 0.5369\n",
      "Epoch 64/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8015 - accuracy: 0.5482 - val_loss: 0.8137 - val_accuracy: 0.5533\n",
      "Epoch 65/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7957 - accuracy: 0.5400 - val_loss: 0.8176 - val_accuracy: 0.5214\n",
      "Epoch 66/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8036 - accuracy: 0.5263 - val_loss: 0.8231 - val_accuracy: 0.5214\n",
      "Epoch 67/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7997 - accuracy: 0.5394 - val_loss: 0.8207 - val_accuracy: 0.5424\n",
      "Epoch 68/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7958 - accuracy: 0.5333 - val_loss: 0.8145 - val_accuracy: 0.5415\n",
      "Epoch 69/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7964 - accuracy: 0.5488 - val_loss: 0.8044 - val_accuracy: 0.5433\n",
      "Epoch 70/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7929 - accuracy: 0.5476 - val_loss: 0.8101 - val_accuracy: 0.5624\n",
      "Epoch 71/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.5464 - val_loss: 0.8017 - val_accuracy: 0.5634\n",
      "Epoch 72/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7978 - accuracy: 0.5363 - val_loss: 0.8510 - val_accuracy: 0.5570\n",
      "Epoch 73/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7943 - accuracy: 0.5409 - val_loss: 0.8167 - val_accuracy: 0.5360\n",
      "Epoch 74/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8011 - accuracy: 0.5217 - val_loss: 0.8151 - val_accuracy: 0.5424\n",
      "Epoch 75/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7957 - accuracy: 0.5382 - val_loss: 0.8212 - val_accuracy: 0.5533\n",
      "Epoch 76/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7936 - accuracy: 0.5436 - val_loss: 0.7997 - val_accuracy: 0.5424\n",
      "Epoch 77/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7958 - accuracy: 0.5518 - val_loss: 0.8150 - val_accuracy: 0.5533\n",
      "Epoch 78/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7985 - accuracy: 0.5448 - val_loss: 0.8223 - val_accuracy: 0.5369\n",
      "Epoch 79/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7895 - accuracy: 0.5482 - val_loss: 0.8180 - val_accuracy: 0.5570\n",
      "Epoch 80/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7920 - accuracy: 0.5558 - val_loss: 0.8226 - val_accuracy: 0.5579\n",
      "Epoch 81/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7868 - accuracy: 0.5561 - val_loss: 0.8232 - val_accuracy: 0.5415\n",
      "Epoch 82/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7904 - accuracy: 0.5375 - val_loss: 0.8116 - val_accuracy: 0.5597\n",
      "Epoch 83/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7881 - accuracy: 0.5455 - val_loss: 0.8114 - val_accuracy: 0.5497\n",
      "Epoch 84/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7983 - accuracy: 0.5415 - val_loss: 0.8139 - val_accuracy: 0.5533\n",
      "Epoch 85/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7957 - accuracy: 0.5382 - val_loss: 0.8170 - val_accuracy: 0.5460\n",
      "Epoch 86/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7928 - accuracy: 0.5488 - val_loss: 0.8124 - val_accuracy: 0.5460\n",
      "Epoch 87/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7918 - accuracy: 0.5412 - val_loss: 0.8096 - val_accuracy: 0.5743\n",
      "Epoch 88/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7864 - accuracy: 0.5455 - val_loss: 0.8163 - val_accuracy: 0.5506\n",
      "Epoch 89/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7882 - accuracy: 0.5500 - val_loss: 0.8041 - val_accuracy: 0.5697\n",
      "Epoch 90/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7856 - accuracy: 0.5485 - val_loss: 0.8221 - val_accuracy: 0.5360\n",
      "Epoch 91/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7910 - accuracy: 0.5537 - val_loss: 0.8226 - val_accuracy: 0.5643\n",
      "Epoch 92/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7908 - accuracy: 0.5524 - val_loss: 0.8123 - val_accuracy: 0.5634\n",
      "Epoch 93/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7989 - accuracy: 0.5199 - val_loss: 0.8046 - val_accuracy: 0.5615\n",
      "Epoch 94/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7979 - accuracy: 0.5430 - val_loss: 0.8313 - val_accuracy: 0.5077\n",
      "Epoch 95/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8044 - accuracy: 0.5321 - val_loss: 0.8539 - val_accuracy: 0.5333\n",
      "Epoch 96/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.5531 - val_loss: 0.8209 - val_accuracy: 0.5606\n",
      "Epoch 97/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7995 - accuracy: 0.5397 - val_loss: 0.8121 - val_accuracy: 0.5643\n",
      "Epoch 98/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7977 - accuracy: 0.5503 - val_loss: 0.8277 - val_accuracy: 0.5606\n",
      "Epoch 99/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7915 - accuracy: 0.5531 - val_loss: 0.8156 - val_accuracy: 0.5606\n",
      "Epoch 100/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7934 - accuracy: 0.5461 - val_loss: 0.8106 - val_accuracy: 0.5697\n",
      "Epoch 101/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7882 - accuracy: 0.5509 - val_loss: 0.8091 - val_accuracy: 0.5652\n",
      "Epoch 102/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7906 - accuracy: 0.5455 - val_loss: 0.8193 - val_accuracy: 0.5579\n",
      "Epoch 103/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8023 - accuracy: 0.5333 - val_loss: 0.8760 - val_accuracy: 0.4959\n",
      "Epoch 104/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7978 - accuracy: 0.5491 - val_loss: 0.8280 - val_accuracy: 0.5652\n",
      "Epoch 105/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8095 - accuracy: 0.5385 - val_loss: 0.8199 - val_accuracy: 0.5515\n",
      "Epoch 106/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7868 - accuracy: 0.5503 - val_loss: 0.8243 - val_accuracy: 0.5415\n",
      "Epoch 107/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7926 - accuracy: 0.5470 - val_loss: 0.8316 - val_accuracy: 0.5460\n",
      "Epoch 108/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7944 - accuracy: 0.5418 - val_loss: 0.8205 - val_accuracy: 0.4977\n",
      "Epoch 109/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7908 - accuracy: 0.5509 - val_loss: 0.8125 - val_accuracy: 0.5451\n",
      "Epoch 110/110\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7874 - accuracy: 0.5521 - val_loss: 0.8178 - val_accuracy: 0.5670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c2db0d2b60>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],))) # Dodaj warstw wejciow\n",
    "model.add(Dense(256, activation='relu'))  # Dodaj warstw ukryt\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # Dodaj warstw wyjciow z funkcj aktywacji softmax\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=110, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a50e524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "NN_pred = model.predict(X_test)\n",
    "NN_pred_F = model.predict(X_F)\n",
    "y_pred_nn = np.argmax(NN_pred, axis=1)\n",
    "y_pred_nn_F = np.argmax(NN_pred_F, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a1ef7025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_nn, [\"lose\",\"draw\",\"win\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f1a8fe2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_F, y_pred_nn_F, [\"lose\",\"draw\",\"win\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b87b5574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5524515415110481"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_nn, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "362f3913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5515476144831771"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_F, y_pred_nn_F, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781ea9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
